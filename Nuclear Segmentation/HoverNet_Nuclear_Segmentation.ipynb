{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclear Segmentation using HoverNet\n",
    "\n",
    "This notebook implements nuclear segmentation for cervical cancer cell classification using the HoverNet model.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- Base Directory: `Augmented Dataset - Limited Enhancement`\n",
    "- Classes: `im_Dyskeratotic`, `im_Koilocytotic`, `im_Metaplastic`, `im_Parabasal`, `im_Superficial-Intermediate`\n",
    "- Images Location: `<class_folder>/NLM_CLAHE/*.bmp`\n",
    "\n",
    "**Reference:** [HoverNet GitHub](https://github.com/vqdang/hover_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"✓ Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"ℹ Not running on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "if IN_COLAB:\n",
    "    print(\"Installing dependencies...\")\n",
    "    !pip install -q opencv-python-headless\n",
    "    !pip install -q scikit-image\n",
    "    !pip install -q scipy\n",
    "    !pip install -q matplotlib\n",
    "    !pip install -q tqdm\n",
    "    !pip install -q imageio\n",
    "    !pip install -q pillow\n",
    "    \n",
    "    # Install PyTorch (HoverNet uses PyTorch)\n",
    "    !pip install -q torch torchvision\n",
    "    \n",
    "    print(\"\\n✓ Dependencies installed successfully\")\n",
    "else:\n",
    "    print(\"Skipping dependency installation (not on Colab)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone HoverNet repository\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    if not os.path.exists('hover_net'):\n",
    "        print(\"Cloning HoverNet repository...\")\n",
    "        !git clone -q https://github.com/vqdang/hover_net.git\n",
    "        print(\"✓ HoverNet repository cloned\")\n",
    "    else:\n",
    "        print(\"✓ HoverNet repository already exists\")\n",
    "    \n",
    "    # Add HoverNet to Python path\n",
    "    import sys\n",
    "    if '/content/hover_net' not in sys.path:\n",
    "        sys.path.insert(0, '/content/hover_net')\n",
    "    print(\"✓ HoverNet added to Python path\")\n",
    "else:\n",
    "    print(\"Skipping HoverNet clone (not on Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"\\n✓ Google Drive mounted successfully\")\n",
    "else:\n",
    "    print(\"Skipping Google Drive mount (not on Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try importing torch\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"✓ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✓ CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"⚠ PyTorch not found. Please install it.\")\n",
    "\n",
    "print(f\"✓ OpenCV version: {cv2.__version__}\")\n",
    "print(f\"✓ NumPy version: {np.__version__}\")\n",
    "print(\"\\n✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration and Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - UPDATE THESE PATHS AS NEEDED\n",
    "# ============================================================================\n",
    "\n",
    "# Google Drive base path\n",
    "DRIVE_BASE_PATH = '/content/drive/MyDrive'\n",
    "\n",
    "# HoverNet weights directory (USER PROVIDED PATH)\n",
    "WEIGHTS_DIR = '/content/drive/MyDrive/Projects/6_Project Phoenix_Cervical Cancer Cell Classification/Explainability Worflows/Nucleus Masking/Hovernet Weights'\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = 'Augmented Dataset - Limited Enhancement'\n",
    "DATASET_BASE_PATH = os.path.join(DRIVE_BASE_PATH, DATASET_NAME)\n",
    "\n",
    "# Cell classes\n",
    "CELL_CLASSES = [\n",
    "    'im_Dyskeratotic',\n",
    "    'im_Koilocytotic',\n",
    "    'im_Metaplastic',\n",
    "    'im_Parabasal',\n",
    "    'im_Superficial-Intermediate'\n",
    "]\n",
    "\n",
    "# Subfolder containing images\n",
    "IMAGE_SUBFOLDER = 'NLM_CLAHE'\n",
    "\n",
    "# Output directory for segmentation results\n",
    "OUTPUT_BASE_PATH = os.path.join(DRIVE_BASE_PATH, 'HoverNet_Segmentation_Results')\n",
    "os.makedirs(OUTPUT_BASE_PATH, exist_ok=True)\n",
    "\n",
    "# Temporary directory for HoverNet processing\n",
    "TEMP_DIR = '/content/temp_hovernet'\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Weights directory: {WEIGHTS_DIR}\")\n",
    "print(f\"Dataset base path: {DATASET_BASE_PATH}\")\n",
    "print(f\"Output base path: {OUTPUT_BASE_PATH}\")\n",
    "print(f\"Temp directory: {TEMP_DIR}\")\n",
    "print(f\"\\nCell classes to process: {len(CELL_CLASSES)}\")\n",
    "for i, cell_class in enumerate(CELL_CLASSES, 1):\n",
    "    print(f\"  {i}. {cell_class}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Paths and Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify weights directory\n",
    "def verify_weights():\n",
    "    \"\"\"Verify HoverNet weights are available.\"\"\"\n",
    "    print(\"Verifying HoverNet weights...\\n\")\n",
    "    \n",
    "    if not os.path.exists(WEIGHTS_DIR):\n",
    "        print(f\"❌ ERROR: Weights directory not found: {WEIGHTS_DIR}\")\n",
    "        print(\"\\nPlease update WEIGHTS_DIR to the correct path.\")\n",
    "        return False, None\n",
    "    \n",
    "    # List all files in weights directory\n",
    "    weight_files = os.listdir(WEIGHTS_DIR)\n",
    "    print(f\"✓ Weights directory found\")\n",
    "    print(f\"\\nFiles in weights directory ({len(weight_files)} files):\")\n",
    "    \n",
    "    model_files = []\n",
    "    for f in weight_files:\n",
    "        print(f\"  - {f}\")\n",
    "        if f.endswith(('.pth', '.tar', '.ckpt', '.pt')):\n",
    "            model_files.append(f)\n",
    "    \n",
    "    if not model_files:\n",
    "        print(\"\\n⚠ WARNING: No model files (.pth, .tar, .ckpt, .pt) found in weights directory\")\n",
    "        return False, None\n",
    "    \n",
    "    print(f\"\\n✓ Found {len(model_files)} model file(s)\")\n",
    "    \n",
    "    # Use the first model file found\n",
    "    model_path = os.path.join(WEIGHTS_DIR, model_files[0])\n",
    "    print(f\"✓ Will use model: {model_files[0]}\")\n",
    "    \n",
    "    return True, model_path\n",
    "\n",
    "\n",
    "# Verify dataset\n",
    "def verify_dataset():\n",
    "    \"\"\"Verify dataset structure and count images per class.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Verifying dataset structure...\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    if not os.path.exists(DATASET_BASE_PATH):\n",
    "        print(f\"❌ ERROR: Dataset base path not found: {DATASET_BASE_PATH}\")\n",
    "        print(\"\\nPlease update DATASET_BASE_PATH in the configuration cell.\")\n",
    "        return False, None\n",
    "    \n",
    "    total_images = 0\n",
    "    class_image_counts = {}\n",
    "    \n",
    "    for cell_class in CELL_CLASSES:\n",
    "        class_path = os.path.join(DATASET_BASE_PATH, cell_class)\n",
    "        image_path = os.path.join(class_path, IMAGE_SUBFOLDER)\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"❌ WARNING: Image path not found: {image_path}\")\n",
    "            class_image_counts[cell_class] = 0\n",
    "            continue\n",
    "        \n",
    "        # Count .bmp files\n",
    "        bmp_files = glob.glob(os.path.join(image_path, '*.bmp'))\n",
    "        count = len(bmp_files)\n",
    "        class_image_counts[cell_class] = count\n",
    "        total_images += count\n",
    "        \n",
    "        print(f\"✓ {cell_class:40s}: {count:5d} images\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Total images to process: {total_images}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return total_images > 0, class_image_counts\n",
    "\n",
    "\n",
    "# Run verifications\n",
    "weights_valid, model_path = verify_weights()\n",
    "dataset_valid, image_counts = verify_dataset()\n",
    "\n",
    "if weights_valid and dataset_valid:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✓ ALL VERIFICATIONS PASSED - READY TO PROCESS\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"❌ VERIFICATION FAILED - PLEASE FIX ERRORS ABOVE\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. HoverNet Model Setup and Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HoverNet modules\n",
    "try:\n",
    "    # Try to import infer modules from HoverNet\n",
    "    import importlib.util\n",
    "    \n",
    "    # Check if we can load the infer module\n",
    "    infer_tile_path = '/content/hover_net/infer/tile.py'\n",
    "    if os.path.exists(infer_tile_path):\n",
    "        spec = importlib.util.spec_from_file_location(\"infer.tile\", infer_tile_path)\n",
    "        infer_tile = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(infer_tile)\n",
    "        print(\"✓ HoverNet inference module loaded\")\n",
    "    else:\n",
    "        print(\"ℹ HoverNet inference module not found at expected location\")\n",
    "        print(\"  Will use command-line interface instead\")\n",
    "except Exception as e:\n",
    "    print(f\"ℹ Could not import HoverNet modules: {e}\")\n",
    "    print(\"  Will use command-line interface instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup HoverNet inference using command-line interface\n",
    "def setup_hovernet_inference():\n",
    "    \"\"\"\n",
    "    Setup HoverNet for inference using the run_infer.py script.\n",
    "    This is the most reliable method that works with the official weights.\n",
    "    \"\"\"\n",
    "    hovernet_dir = '/content/hover_net'\n",
    "    run_infer_script = os.path.join(hovernet_dir, 'run_infer.py')\n",
    "    \n",
    "    if not os.path.exists(run_infer_script):\n",
    "        print(f\"❌ ERROR: run_infer.py not found at {run_infer_script}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"✓ HoverNet inference script found: {run_infer_script}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def run_hovernet_inference(image, image_name):\n",
    "    \"\"\"\n",
    "    Run HoverNet inference on a single image using the command-line interface.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image array (H x W x 3)\n",
    "        image_name: Name of the image file (for temp storage)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Segmentation results containing:\n",
    "            - 'instance_map': Instance segmentation map\n",
    "            - 'type_map': Cell type classification map (if available)\n",
    "            - 'num_nuclei': Number of detected nuclei\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create temporary directories\n",
    "        temp_input_dir = os.path.join(TEMP_DIR, 'input')\n",
    "        temp_output_dir = os.path.join(TEMP_DIR, 'output')\n",
    "        os.makedirs(temp_input_dir, exist_ok=True)\n",
    "        os.makedirs(temp_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save image temporarily\n",
    "        base_name = os.path.splitext(image_name)[0]\n",
    "        temp_image_path = os.path.join(temp_input_dir, f\"{base_name}.png\")\n",
    "        cv2.imwrite(temp_image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # Run HoverNet inference\n",
    "        hovernet_dir = '/content/hover_net'\n",
    "        cmd = [\n",
    "            'python', os.path.join(hovernet_dir, 'run_infer.py'),\n",
    "            '--gpu=0' if torch.cuda.is_available() else '--gpu=-1',\n",
    "            f'--nr_types=0',  # No type classification, just segmentation\n",
    "            f'--model_path={model_path}',\n",
    "            f'--model_mode=fast',  # Use fast mode\n",
    "            f'--nr_inference_workers=4',\n",
    "            f'--nr_post_proc_workers=4',\n",
    "            'tile',\n",
    "            f'--input_dir={temp_input_dir}',\n",
    "            f'--output_dir={temp_output_dir}',\n",
    "            '--draw_dot',\n",
    "            '--save_qupath'\n",
    "        ]\n",
    "        \n",
    "        # Run the command silently\n",
    "        import subprocess\n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            cwd=hovernet_dir,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        # Check if inference was successful\n",
    "        mat_file = os.path.join(temp_output_dir, 'mat', f\"{base_name}.mat\")\n",
    "        json_file = os.path.join(temp_output_dir, 'json', f\"{base_name}.json\")\n",
    "        \n",
    "        if os.path.exists(json_file):\n",
    "            # Load the JSON output which contains nuclei information\n",
    "            with open(json_file, 'r') as f:\n",
    "                nuclei_dict = json.load(f)\n",
    "            \n",
    "            # Create instance map from nuclei dictionary\n",
    "            instance_map = np.zeros(image.shape[:2], dtype=np.uint16)\n",
    "            \n",
    "            nuc_info = nuclei_dict.get('nuc', {})\n",
    "            num_nuclei = len(nuc_info)\n",
    "            \n",
    "            for nuc_id, nuc_data in nuc_info.items():\n",
    "                contour = nuc_data.get('contour', [])\n",
    "                if contour:\n",
    "                    contour_array = np.array(contour, dtype=np.int32)\n",
    "                    cv2.fillPoly(instance_map, [contour_array], int(nuc_id))\n",
    "            \n",
    "            # Clean up temp files\n",
    "            shutil.rmtree(temp_input_dir)\n",
    "            shutil.rmtree(temp_output_dir)\n",
    "            \n",
    "            return {\n",
    "                'instance_map': instance_map,\n",
    "                'type_map': None,\n",
    "                'num_nuclei': num_nuclei,\n",
    "                'nuclei_info': nuc_info\n",
    "            }\n",
    "        else:\n",
    "            # If HoverNet fails, fallback to simple segmentation\n",
    "            print(f\"⚠ HoverNet inference failed for {image_name}, using fallback\")\n",
    "            return fallback_segmentation(image)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error during HoverNet inference: {e}\")\n",
    "        return fallback_segmentation(image)\n",
    "\n",
    "\n",
    "def fallback_segmentation(image):\n",
    "    \"\"\"\n",
    "    Fallback segmentation method using traditional computer vision.\n",
    "    Used when HoverNet inference fails.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image array\n",
    "        \n",
    "    Returns:\n",
    "        dict: Basic segmentation results\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply CLAHE for better contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Otsu's thresholding\n",
    "    _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours by area (remove noise)\n",
    "    min_area = 50\n",
    "    max_area = 5000\n",
    "    valid_contours = [c for c in contours if min_area < cv2.contourArea(c) < max_area]\n",
    "    \n",
    "    # Create instance map\n",
    "    instance_map = np.zeros(image.shape[:2], dtype=np.uint16)\n",
    "    for idx, contour in enumerate(valid_contours, start=1):\n",
    "        cv2.drawContours(instance_map, [contour], -1, idx, -1)\n",
    "    \n",
    "    return {\n",
    "        'instance_map': instance_map,\n",
    "        'type_map': None,\n",
    "        'num_nuclei': len(valid_contours)\n",
    "    }\n",
    "\n",
    "\n",
    "# Verify HoverNet setup\n",
    "hovernet_ready = setup_hovernet_inference()\n",
    "if hovernet_ready:\n",
    "    print(\"\\n✓ HoverNet inference is ready\")\n",
    "else:\n",
    "    print(\"\\n⚠ HoverNet inference setup incomplete\")\n",
    "    print(\"  Will use fallback segmentation method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Image Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load a .bmp image and convert to RGB.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: RGB image\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "def preprocess_for_hovernet(image):\n",
    "    \"\"\"\n",
    "    Preprocess image for HoverNet inference.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image array\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed image\n",
    "    \"\"\"\n",
    "    # HoverNet expects images in RGB format with values in [0, 255]\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def create_overlay(image, mask, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Create an overlay of the segmentation mask on the original image.\n",
    "    \n",
    "    Args:\n",
    "        image: Original RGB image\n",
    "        mask: Segmentation mask\n",
    "        alpha: Transparency factor\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Overlay image\n",
    "    \"\"\"\n",
    "    # Create a colorized version of the mask\n",
    "    colored_mask = np.zeros_like(image)\n",
    "    \n",
    "    # Get unique instance IDs\n",
    "    unique_instances = np.unique(mask)\n",
    "    unique_instances = unique_instances[unique_instances > 0]  # Skip background\n",
    "    \n",
    "    # Use a fixed random seed for reproducible colors\n",
    "    np.random.seed(42)\n",
    "    colors = np.random.randint(50, 255, size=(len(unique_instances), 3))\n",
    "    \n",
    "    for idx, instance_id in enumerate(unique_instances):\n",
    "        colored_mask[mask == instance_id] = colors[idx]\n",
    "    \n",
    "    # Blend original image with colored mask\n",
    "    overlay = cv2.addWeighted(image, 1-alpha, colored_mask, alpha, 0)\n",
    "    \n",
    "    # Draw contours for better visibility\n",
    "    contours, _ = cv2.findContours(\n",
    "        (mask > 0).astype(np.uint8),\n",
    "        cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    cv2.drawContours(overlay, contours, -1, (255, 255, 0), 1)\n",
    "    \n",
    "    return overlay\n",
    "\n",
    "\n",
    "def save_segmentation_result(output_dir, image_name, original_image, segmentation_mask):\n",
    "    \"\"\"\n",
    "    Save segmentation results including original image, mask, and overlay.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save results\n",
    "        image_name: Name of the original image\n",
    "        original_image: Original RGB image\n",
    "        segmentation_mask: Segmentation mask from HoverNet\n",
    "        \n",
    "    Returns:\n",
    "        dict: Paths to saved files\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    base_name = os.path.splitext(image_name)[0]\n",
    "    \n",
    "    # Save original image\n",
    "    original_path = os.path.join(output_dir, f\"{base_name}_original.png\")\n",
    "    cv2.imwrite(original_path, cv2.cvtColor(original_image, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    # Save segmentation mask (as 16-bit to preserve instance IDs)\n",
    "    mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")\n",
    "    cv2.imwrite(mask_path, segmentation_mask.astype(np.uint16))\n",
    "    \n",
    "    # Create and save overlay\n",
    "    overlay = create_overlay(original_image, segmentation_mask)\n",
    "    overlay_path = os.path.join(output_dir, f\"{base_name}_overlay.png\")\n",
    "    cv2.imwrite(overlay_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    return {\n",
    "        'original': original_path,\n",
    "        'mask': mask_path,\n",
    "        'overlay': overlay_path\n",
    "    }\n",
    "\n",
    "print(\"✓ Image processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single image through the HoverNet pipeline.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to input image\n",
    "        output_dir: Directory to save results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing results and statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load image\n",
    "        image = load_image(image_path)\n",
    "        \n",
    "        # Preprocess\n",
    "        preprocessed = preprocess_for_hovernet(image)\n",
    "        \n",
    "        # Run HoverNet inference\n",
    "        image_name = os.path.basename(image_path)\n",
    "        results = run_hovernet_inference(preprocessed, image_name)\n",
    "        \n",
    "        # Save results\n",
    "        saved_paths = save_segmentation_result(\n",
    "            output_dir,\n",
    "            image_name,\n",
    "            image,\n",
    "            results['instance_map']\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'image_path': image_path,\n",
    "            'image_name': image_name,\n",
    "            'num_nuclei': results['num_nuclei'],\n",
    "            'saved_paths': saved_paths,\n",
    "            'error': None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'image_path': image_path,\n",
    "            'image_name': os.path.basename(image_path),\n",
    "            'num_nuclei': 0,\n",
    "            'saved_paths': None,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "def process_cell_class(cell_class, max_images=None, progress_bar=True):\n",
    "    \"\"\"\n",
    "    Process all images for a specific cell class.\n",
    "    \n",
    "    Args:\n",
    "        cell_class: Name of the cell class\n",
    "        max_images: Maximum number of images to process (None for all)\n",
    "        progress_bar: Whether to show progress bar\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing statistics\n",
    "    \"\"\"\n",
    "    # Setup paths\n",
    "    input_dir = os.path.join(DATASET_BASE_PATH, cell_class, IMAGE_SUBFOLDER)\n",
    "    output_dir = os.path.join(OUTPUT_BASE_PATH, cell_class)\n",
    "    \n",
    "    # Get all .bmp files\n",
    "    image_files = sorted(glob.glob(os.path.join(input_dir, '*.bmp')))\n",
    "    \n",
    "    # Limit number of images if specified\n",
    "    if max_images is not None:\n",
    "        image_files = image_files[:max_images]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing {cell_class}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Input directory: {input_dir}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"Number of images: {len(image_files)}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Process each image\n",
    "    results = []\n",
    "    \n",
    "    if progress_bar:\n",
    "        iterator = tqdm(image_files, desc=f\"Processing {cell_class}\")\n",
    "    else:\n",
    "        iterator = image_files\n",
    "    \n",
    "    for image_path in iterator:\n",
    "        result = process_single_image(image_path, output_dir)\n",
    "        results.append(result)\n",
    "        \n",
    "        if not result['success'] and not progress_bar:\n",
    "            print(f\"❌ Error processing {result['image_name']}: {result['error']}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    failed = len(results) - successful\n",
    "    total_nuclei = sum(r['num_nuclei'] for r in results if r['success'])\n",
    "    avg_nuclei = total_nuclei / successful if successful > 0 else 0\n",
    "    \n",
    "    stats = {\n",
    "        'cell_class': cell_class,\n",
    "        'total_images': len(image_files),\n",
    "        'successful': successful,\n",
    "        'failed': failed,\n",
    "        'total_nuclei': total_nuclei,\n",
    "        'avg_nuclei_per_image': avg_nuclei,\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Summary for {cell_class}:\")\n",
    "    print(f\"  Total images: {stats['total_images']}\")\n",
    "    print(f\"  Successful: {stats['successful']}\")\n",
    "    print(f\"  Failed: {stats['failed']}\")\n",
    "    print(f\"  Total nuclei detected: {stats['total_nuclei']}\")\n",
    "    print(f\"  Average nuclei per image: {stats['avg_nuclei_per_image']:.2f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def process_all_classes(max_images_per_class=None):\n",
    "    \"\"\"\n",
    "    Process all cell classes in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        max_images_per_class: Maximum images per class (None for all)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Complete processing statistics\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING BATCH PROCESSING OF ALL CELL CLASSES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    all_stats = {}\n",
    "    \n",
    "    for cell_class in CELL_CLASSES:\n",
    "        stats = process_cell_class(cell_class, max_images=max_images_per_class)\n",
    "        all_stats[cell_class] = stats\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    processing_time = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_images = sum(stats['total_images'] for stats in all_stats.values())\n",
    "    total_successful = sum(stats['successful'] for stats in all_stats.values())\n",
    "    total_failed = sum(stats['failed'] for stats in all_stats.values())\n",
    "    total_nuclei = sum(stats['total_nuclei'] for stats in all_stats.values())\n",
    "    \n",
    "    overall_stats = {\n",
    "        'start_time': start_time.isoformat(),\n",
    "        'end_time': end_time.isoformat(),\n",
    "        'processing_time_seconds': processing_time,\n",
    "        'total_images': total_images,\n",
    "        'total_successful': total_successful,\n",
    "        'total_failed': total_failed,\n",
    "        'total_nuclei_detected': total_nuclei,\n",
    "        'avg_nuclei_per_image': total_nuclei / total_successful if total_successful > 0 else 0,\n",
    "        'class_statistics': all_stats\n",
    "    }\n",
    "    \n",
    "    # Save overall statistics\n",
    "    stats_file = os.path.join(OUTPUT_BASE_PATH, 'processing_statistics.json')\n",
    "    with open(stats_file, 'w') as f:\n",
    "        # Remove detailed results to keep file size manageable\n",
    "        stats_to_save = overall_stats.copy()\n",
    "        for class_name in stats_to_save['class_statistics']:\n",
    "            stats_to_save['class_statistics'][class_name].pop('results', None)\n",
    "        json.dump(stats_to_save, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OVERALL PROCESSING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Successful: {total_successful}\")\n",
    "    print(f\"Failed: {total_failed}\")\n",
    "    print(f\"Total nuclei detected: {total_nuclei}\")\n",
    "    print(f\"Average nuclei per image: {overall_stats['avg_nuclei_per_image']:.2f}\")\n",
    "    print(f\"Processing time: {processing_time:.2f} seconds ({processing_time/60:.2f} minutes)\")\n",
    "    print(f\"Statistics saved to: {stats_file}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return overall_stats\n",
    "\n",
    "print(\"✓ Batch processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_results(cell_class, num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualize sample segmentation results for a cell class.\n",
    "    \n",
    "    Args:\n",
    "        cell_class: Name of the cell class\n",
    "        num_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    output_dir = os.path.join(OUTPUT_BASE_PATH, cell_class)\n",
    "    \n",
    "    # Get sample overlay images\n",
    "    overlay_files = sorted(glob.glob(os.path.join(output_dir, '*_overlay.png')))\n",
    "    \n",
    "    if not overlay_files:\n",
    "        print(f\"No results found for {cell_class}\")\n",
    "        return\n",
    "    \n",
    "    # Select samples\n",
    "    import random\n",
    "    samples = random.sample(overlay_files, min(num_samples, len(overlay_files)))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, len(samples), figsize=(5*len(samples), 5))\n",
    "    if len(samples) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, overlay_path in enumerate(samples):\n",
    "        overlay = cv2.imread(overlay_path)\n",
    "        overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[idx].imshow(overlay_rgb)\n",
    "        base_name = os.path.basename(overlay_path).replace('_overlay.png', '')\n",
    "        axes[idx].set_title(f\"{cell_class.replace('im_', '')}\\n{base_name}\", fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_statistics(stats):\n",
    "    \"\"\"\n",
    "    Plot processing statistics across all cell classes.\n",
    "    \n",
    "    Args:\n",
    "        stats: Overall statistics dictionary\n",
    "    \"\"\"\n",
    "    class_stats = stats['class_statistics']\n",
    "    \n",
    "    cell_classes = list(class_stats.keys())\n",
    "    class_labels = [c.replace('im_', '') for c in cell_classes]\n",
    "    nuclei_counts = [class_stats[c]['total_nuclei'] for c in cell_classes]\n",
    "    avg_nuclei = [class_stats[c]['avg_nuclei_per_image'] for c in cell_classes]\n",
    "    image_counts = [class_stats[c]['total_images'] for c in cell_classes]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Plot 1: Total nuclei per class\n",
    "    axes[0, 0].bar(range(len(cell_classes)), nuclei_counts, color='steelblue')\n",
    "    axes[0, 0].set_xlabel('Cell Class', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Total Nuclei Detected', fontsize=12)\n",
    "    axes[0, 0].set_title('Total Nuclei Detected per Cell Class', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xticks(range(len(cell_classes)))\n",
    "    axes[0, 0].set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Average nuclei per image\n",
    "    axes[0, 1].bar(range(len(cell_classes)), avg_nuclei, color='coral')\n",
    "    axes[0, 1].set_xlabel('Cell Class', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Average Nuclei per Image', fontsize=12)\n",
    "    axes[0, 1].set_title('Average Nuclei per Image by Cell Class', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xticks(range(len(cell_classes)))\n",
    "    axes[0, 1].set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Number of images per class\n",
    "    axes[1, 0].bar(range(len(cell_classes)), image_counts, color='mediumseagreen')\n",
    "    axes[1, 0].set_xlabel('Cell Class', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Number of Images', fontsize=12)\n",
    "    axes[1, 0].set_title('Number of Images per Cell Class', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xticks(range(len(cell_classes)))\n",
    "    axes[1, 0].set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Success rate per class\n",
    "    success_rates = [\n",
    "        (class_stats[c]['successful'] / class_stats[c]['total_images'] * 100)\n",
    "        if class_stats[c]['total_images'] > 0 else 0\n",
    "        for c in cell_classes\n",
    "    ]\n",
    "    axes[1, 1].bar(range(len(cell_classes)), success_rates, color='mediumpurple')\n",
    "    axes[1, 1].set_xlabel('Cell Class', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Success Rate (%)', fontsize=12)\n",
    "    axes[1, 1].set_title('Processing Success Rate by Cell Class', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xticks(range(len(cell_classes)))\n",
    "    axes[1, 1].set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "    axes[1, 1].set_ylim([0, 105])\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"✓ Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Processing\n",
    "\n",
    "### Test Run (Optional)\n",
    "\n",
    "First, test on a small number of images to ensure everything works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single class with limited images\n",
    "if weights_valid and dataset_valid:\n",
    "    print(\"Running test on first cell class with 5 images...\\n\")\n",
    "    test_stats = process_cell_class(CELL_CLASSES[0], max_images=5)\n",
    "    \n",
    "    if test_stats['successful'] > 0:\n",
    "        print(\"\\n✓ Test completed successfully!\")\n",
    "        print(\"\\nVisualizing test results:\")\n",
    "        visualize_sample_results(CELL_CLASSES[0], num_samples=min(3, test_stats['successful']))\n",
    "    else:\n",
    "        print(\"\\n❌ Test failed. Please check errors above.\")\n",
    "else:\n",
    "    print(\"❌ Cannot run test - verification failed. Please fix errors in previous cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Processing\n",
    "\n",
    "**⚠️ WARNING:** This will process ALL images in the dataset. Depending on the dataset size, this may take a long time!\n",
    "\n",
    "Uncomment and run the cell below to process all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNCOMMENT TO RUN FULL PROCESSING\n",
    "# if weights_valid and dataset_valid:\n",
    "#     # Process all images\n",
    "#     overall_stats = process_all_classes()\n",
    "# else:\n",
    "#     print(\"❌ Cannot run processing - verification failed. Please fix errors above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Processing (Recommended)\n",
    "\n",
    "Process a limited number of images per class for testing or quick analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process limited number of images per class (e.g., 50 images per class)\n",
    "if weights_valid and dataset_valid:\n",
    "    MAX_IMAGES_PER_CLASS = 50  # Adjust this number as needed\n",
    "    \n",
    "    print(f\"Processing up to {MAX_IMAGES_PER_CLASS} images per class...\\n\")\n",
    "    overall_stats = process_all_classes(max_images_per_class=MAX_IMAGES_PER_CLASS)\n",
    "else:\n",
    "    print(\"❌ Cannot run processing - verification failed. Please fix errors above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample results for each class\n",
    "if 'overall_stats' in locals():\n",
    "    print(\"\\nVisualizing sample results for each class:\\n\")\n",
    "    \n",
    "    for cell_class in CELL_CLASSES:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Sample results for {cell_class}:\")\n",
    "        print(f\"{'='*70}\")\n",
    "        visualize_sample_results(cell_class, num_samples=3)\n",
    "else:\n",
    "    print(\"No results to visualize. Please run processing first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overall statistics\n",
    "if 'overall_stats' in locals():\n",
    "    print(\"\\nPlotting overall statistics:\\n\")\n",
    "    plot_statistics(overall_stats)\n",
    "else:\n",
    "    print(\"No statistics to plot. Please run processing first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_report(stats):\n",
    "    \"\"\"\n",
    "    Create a formatted summary report of the processing results.\n",
    "    \n",
    "    Args:\n",
    "        stats: Overall statistics dictionary\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted report\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(\"HoverNet Nuclear Segmentation - Processing Report\")\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(f\"\\nProcessing Date: {stats['start_time']}\")\n",
    "    report.append(f\"Total Processing Time: {stats['processing_time_seconds']:.2f} seconds ({stats['processing_time_seconds']/60:.2f} minutes)\")\n",
    "    report.append(f\"\\nDataset: {DATASET_NAME}\")\n",
    "    report.append(f\"Output Location: {OUTPUT_BASE_PATH}\")\n",
    "    report.append(f\"Weights Location: {WEIGHTS_DIR}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"OVERALL STATISTICS\")\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(f\"Total Images Processed: {stats['total_images']}\")\n",
    "    report.append(f\"Successful: {stats['total_successful']} ({stats['total_successful']/stats['total_images']*100:.1f}%)\")\n",
    "    report.append(f\"Failed: {stats['total_failed']} ({stats['total_failed']/stats['total_images']*100:.1f}%)\")\n",
    "    report.append(f\"Total Nuclei Detected: {stats['total_nuclei_detected']}\")\n",
    "    report.append(f\"Average Nuclei per Image: {stats['avg_nuclei_per_image']:.2f}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"PER-CLASS STATISTICS\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    for cell_class, class_stats in stats['class_statistics'].items():\n",
    "        report.append(f\"\\n{cell_class}:\")\n",
    "        report.append(f\"  Images Processed: {class_stats['total_images']}\")\n",
    "        report.append(f\"  Successful: {class_stats['successful']} ({class_stats['successful']/class_stats['total_images']*100:.1f}%)\")\n",
    "        report.append(f\"  Failed: {class_stats['failed']}\")\n",
    "        report.append(f\"  Total Nuclei: {class_stats['total_nuclei']}\")\n",
    "        report.append(f\"  Avg Nuclei/Image: {class_stats['avg_nuclei_per_image']:.2f}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"\\nReport generated by HoverNet Nuclear Segmentation Pipeline\")\n",
    "    report.append(f\"Generated at: {datetime.now().isoformat()}\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "\n",
    "# Generate and save report\n",
    "if 'overall_stats' in locals():\n",
    "    report = create_summary_report(overall_stats)\n",
    "    \n",
    "    # Print report\n",
    "    print(report)\n",
    "    \n",
    "    # Save report to file\n",
    "    report_file = os.path.join(OUTPUT_BASE_PATH, 'processing_report.txt')\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(f\"\\n✓ Report saved to: {report_file}\")\n",
    "else:\n",
    "    print(\"No results to report. Please run processing first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files\n",
    "if os.path.exists(TEMP_DIR):\n",
    "    shutil.rmtree(TEMP_DIR)\n",
    "    print(f\"✓ Cleaned up temporary directory: {TEMP_DIR}\")\n",
    "else:\n",
    "    print(\"No temporary files to clean up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Additional Notes\n",
    "\n",
    "### Implementation Details:\n",
    "\n",
    "1. **HoverNet Integration**: This notebook uses the HoverNet command-line interface for maximum compatibility\n",
    "2. **Fallback Mechanism**: If HoverNet fails, a traditional CV-based segmentation is used as fallback\n",
    "3. **Error Handling**: Comprehensive error handling ensures processing continues even if individual images fail\n",
    "4. **GPU Acceleration**: Automatically uses GPU if available for faster processing\n",
    "5. **Memory Management**: Processes images one at a time to avoid memory issues\n",
    "\n",
    "### Output Structure:\n",
    "\n",
    "```\n",
    "HoverNet_Segmentation_Results/\n",
    "├── im_Dyskeratotic/\n",
    "│   ├── image1_original.png\n",
    "│   ├── image1_mask.png\n",
    "│   ├── image1_overlay.png\n",
    "│   └── ...\n",
    "├── im_Koilocytotic/\n",
    "├── im_Metaplastic/\n",
    "├── im_Parabasal/\n",
    "├── im_Superficial-Intermediate/\n",
    "├── processing_statistics.json\n",
    "└── processing_report.txt\n",
    "```\n",
    "\n",
    "### Troubleshooting:\n",
    "\n",
    "1. **Out of Memory**: Reduce batch size or process fewer images at once\n",
    "2. **HoverNet Errors**: Check that weights are compatible with the HoverNet version\n",
    "3. **Slow Processing**: Ensure GPU is being used (check CUDA availability)\n",
    "4. **Missing Results**: Check the error messages in the processing output\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Quality Check**: Manually inspect sample results to ensure segmentation quality\n",
    "2. **Feature Extraction**: Extract morphological features from segmented nuclei\n",
    "3. **Integration**: Integrate results with your classification pipeline\n",
    "4. **Fine-tuning**: Consider fine-tuning HoverNet on cervical cell images for better results\n",
    "\n",
    "### References:\n",
    "\n",
    "- **HoverNet Paper**: Graham, S., et al. \"Hover-Net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images.\" Medical Image Analysis (2019)\n",
    "- **HoverNet GitHub**: https://github.com/vqdang/hover_net\n",
    "- **Project Phoenix**: Cervical Cancer Cell Classification using Explainable AI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclear Segmentation using HoverNet\n",
    "\n",
    "This notebook implements nuclear segmentation for cervical cancer cell classification using the HoverNet model.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- Base Directory: `Augmented Dataset - Limited Enhancement`\n",
    "- Classes: `im_Dyskeratotic`, `im_Koilocytotic`, `im_Metaplastic`, `im_Parabasal`, `im_Superficial-Intermediate`\n",
    "- Images Location: `<class_folder>/NLM_CLAHE/*.bmp`\n",
    "\n",
    "**Reference:** [HoverNet GitHub](https://github.com/vqdang/hover_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"✓ Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"ℹ Not running on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "if IN_COLAB:\n",
    "    print(\"Installing dependencies...\\n\")\n",
    "    \n",
    "    # Core dependencies\n",
    "    !pip install -q opencv-python-headless\n",
    "    !pip install -q scikit-image\n",
    "    !pip install -q scipy\n",
    "    !pip install -q matplotlib\n",
    "    !pip install -q tqdm\n",
    "    !pip install -q pillow\n",
    "    \n",
    "    # PyTorch\n",
    "    !pip install -q torch torchvision\n",
    "    \n",
    "    # HoverNet dependencies\n",
    "    !pip install -q imgaug\n",
    "    !pip install -q termcolor\n",
    "    \n",
    "    print(\"\\n✓ Dependencies installed successfully\")\n",
    "else:\n",
    "    print(\"Skipping dependency installation (not on Colab)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone HoverNet repository\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if IN_COLAB:\n",
    "    HOVERNET_DIR = '/content/hover_net'\n",
    "    \n",
    "    if not os.path.exists(HOVERNET_DIR):\n",
    "        print(\"Cloning HoverNet repository...\")\n",
    "        !git clone https://github.com/vqdang/hover_net.git {HOVERNET_DIR}\n",
    "        print(\"✓ HoverNet repository cloned\")\n",
    "    else:\n",
    "        print(\"✓ HoverNet repository already exists\")\n",
    "    \n",
    "    # Add HoverNet to Python path\n",
    "    if HOVERNET_DIR not in sys.path:\n",
    "        sys.path.insert(0, HOVERNET_DIR)\n",
    "    print(\"✓ HoverNet added to Python path\")\n",
    "else:\n",
    "    HOVERNET_DIR = './hover_net'\n",
    "    print(\"Skipping HoverNet clone (not on Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"\\n✓ Google Drive mounted successfully\")\n",
    "else:\n",
    "    print(\"Skipping Google Drive mount (not on Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import shutil\n",
    "import warnings\n",
    "import traceback\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# SciPy/Scikit-image imports\n",
    "from scipy.ndimage import label as scipy_label\n",
    "from scipy.ndimage import binary_fill_holes, binary_dilation, binary_erosion\n",
    "from scipy import ndimage\n",
    "\n",
    "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(f\"✓ Using device: {DEVICE}\")\n",
    "\n",
    "print(f\"✓ OpenCV version: {cv2.__version__}\")\n",
    "print(f\"✓ NumPy version: {np.__version__}\")\n",
    "print(\"\\n✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - UPDATE THESE PATHS AS NEEDED\n",
    "# ============================================================================\n",
    "\n",
    "# Google Drive base path\n",
    "DRIVE_BASE_PATH = '/content/drive/MyDrive'\n",
    "\n",
    "# HoverNet weights directory (contains the .tar file)\n",
    "WEIGHTS_DIR = '/content/drive/MyDrive/Projects/6_Project Phoenix_Cervical Cancer Cell Classification/Explainability Worflows/Nucleus Masking/Hovernet Weights'\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = 'Augmented Dataset - Limited Enhancement'\n",
    "DATASET_BASE_PATH = os.path.join(DRIVE_BASE_PATH, DATASET_NAME)\n",
    "\n",
    "# Cell classes\n",
    "CELL_CLASSES = [\n",
    "    'im_Dyskeratotic',\n",
    "    'im_Koilocytotic',\n",
    "    'im_Metaplastic',\n",
    "    'im_Parabasal',\n",
    "    'im_Superficial-Intermediate'\n",
    "]\n",
    "\n",
    "# Subfolder containing images\n",
    "IMAGE_SUBFOLDER = 'NLM_CLAHE'\n",
    "\n",
    "# Output directory for segmentation results\n",
    "OUTPUT_BASE_PATH = os.path.join(DRIVE_BASE_PATH, 'HoverNet_Segmentation_Results')\n",
    "os.makedirs(OUTPUT_BASE_PATH, exist_ok=True)\n",
    "\n",
    "# Temporary directory for processing\n",
    "TEMP_DIR = '/content/temp_hovernet'\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "# Debug mode - set to True to see detailed error messages\n",
    "DEBUG_MODE = True\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Weights directory: {WEIGHTS_DIR}\")\n",
    "print(f\"Dataset base path: {DATASET_BASE_PATH}\")\n",
    "print(f\"Output base path: {OUTPUT_BASE_PATH}\")\n",
    "print(f\"Debug mode: {DEBUG_MODE}\")\n",
    "print(f\"\\nCell classes to process: {len(CELL_CLASSES)}\")\n",
    "for i, cell_class in enumerate(CELL_CLASSES, 1):\n",
    "    print(f\"  {i}. {cell_class}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Weights and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weight_file():\n",
    "    \"\"\"Find the HoverNet weight file (.tar) in the weights directory.\"\"\"\n",
    "    print(\"Searching for HoverNet weights...\\n\")\n",
    "    \n",
    "    if not os.path.exists(WEIGHTS_DIR):\n",
    "        print(f\"❌ ERROR: Weights directory not found: {WEIGHTS_DIR}\")\n",
    "        return None\n",
    "    \n",
    "    # List all files\n",
    "    all_files = os.listdir(WEIGHTS_DIR)\n",
    "    print(f\"Files in weights directory:\")\n",
    "    for f in all_files:\n",
    "        file_path = os.path.join(WEIGHTS_DIR, f)\n",
    "        if os.path.isfile(file_path):\n",
    "            size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "            print(f\"  - {f} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Find .tar files\n",
    "    tar_files = [f for f in all_files if f.endswith('.tar')]\n",
    "    \n",
    "    if not tar_files:\n",
    "        print(\"\\n❌ ERROR: No .tar weight files found!\")\n",
    "        return None\n",
    "    \n",
    "    weight_file = os.path.join(WEIGHTS_DIR, tar_files[0])\n",
    "    print(f\"\\n✓ Found weight file: {tar_files[0]}\")\n",
    "    \n",
    "    return weight_file\n",
    "\n",
    "\n",
    "def verify_dataset():\n",
    "    \"\"\"Verify dataset structure and count images.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Verifying dataset...\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    if not os.path.exists(DATASET_BASE_PATH):\n",
    "        print(f\"❌ ERROR: Dataset not found: {DATASET_BASE_PATH}\")\n",
    "        return False, {}\n",
    "    \n",
    "    total_images = 0\n",
    "    class_counts = {}\n",
    "    \n",
    "    for cell_class in CELL_CLASSES:\n",
    "        image_dir = os.path.join(DATASET_BASE_PATH, cell_class, IMAGE_SUBFOLDER)\n",
    "        \n",
    "        if not os.path.exists(image_dir):\n",
    "            print(f\"❌ {cell_class}: Directory not found\")\n",
    "            class_counts[cell_class] = 0\n",
    "            continue\n",
    "        \n",
    "        images = glob.glob(os.path.join(image_dir, '*.bmp'))\n",
    "        count = len(images)\n",
    "        class_counts[cell_class] = count\n",
    "        total_images += count\n",
    "        print(f\"✓ {cell_class:40s}: {count:5d} images\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Total images: {total_images}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    return total_images > 0, class_counts\n",
    "\n",
    "\n",
    "# Run verifications\n",
    "WEIGHT_FILE = find_weight_file()\n",
    "dataset_valid, image_counts = verify_dataset()\n",
    "\n",
    "if WEIGHT_FILE and dataset_valid:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✓ ALL VERIFICATIONS PASSED\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"❌ VERIFICATION FAILED - Please fix errors above\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load HoverNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to import HoverNet model components\n",
    "HOVERNET_MODULES_AVAILABLE = False\n",
    "model = None\n",
    "\n",
    "try:\n",
    "    from hover_net.models.hovernet.net_desc import create_model\n",
    "    print(\"✓ HoverNet model module imported\")\n",
    "    HOVERNET_MODULES_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"⚠ Could not import HoverNet model: {e}\")\n",
    "    print(\"Will use CV-based segmentation instead\")\n",
    "\n",
    "# Try loading the model if modules are available\n",
    "if HOVERNET_MODULES_AVAILABLE and WEIGHT_FILE:\n",
    "    try:\n",
    "        print(f\"\\nLoading model from: {WEIGHT_FILE}\")\n",
    "        \n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(WEIGHT_FILE, map_location=DEVICE)\n",
    "        print(f\"Checkpoint keys: {list(checkpoint.keys())}\")\n",
    "        \n",
    "        # Get state dict\n",
    "        state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "        \n",
    "        # Check if this is a notype model\n",
    "        has_type_head = any('tp.' in k for k in state_dict.keys())\n",
    "        nr_types = None\n",
    "        if has_type_head:\n",
    "            # Find nr_types from tp output layer\n",
    "            for key in state_dict.keys():\n",
    "                if 'tp.u0.conv.weight' in key:\n",
    "                    nr_types = state_dict[key].shape[0]\n",
    "                    break\n",
    "        \n",
    "        print(f\"Has type head: {has_type_head}\")\n",
    "        print(f\"Number of types: {nr_types}\")\n",
    "        \n",
    "        # Determine model mode from state dict keys\n",
    "        mode = 'original'\n",
    "        for key in state_dict.keys():\n",
    "            if 'fast' in key.lower():\n",
    "                mode = 'fast'\n",
    "                break\n",
    "        print(f\"Model mode: {mode}\")\n",
    "        \n",
    "        # Create model\n",
    "        model = create_model(mode=mode, nr_types=nr_types)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model = model.to(DEVICE)\n",
    "        model.eval()\n",
    "        \n",
    "        print(\"\\n✓ HoverNet model loaded successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠ Failed to load HoverNet model: {e}\")\n",
    "        if DEBUG_MODE:\n",
    "            traceback.print_exc()\n",
    "        print(\"Will use CV-based segmentation instead\")\n",
    "        model = None\n",
    "else:\n",
    "    print(\"\\nUsing CV-based segmentation (HoverNet model not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Segmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_nuclei_cv(image):\n",
    "    \"\"\"\n",
    "    Segment nuclei using traditional computer vision methods.\n",
    "    This is a robust fallback that works on any image.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image (H, W, 3) uint8\n",
    "        \n",
    "    Returns:\n",
    "        dict with 'instance_map' and 'num_nuclei'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to different color spaces\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        # Apply CLAHE for contrast enhancement\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        enhanced = clahe.apply(gray)\n",
    "        \n",
    "        # Try multiple thresholding approaches and combine\n",
    "        # Approach 1: Otsu on enhanced grayscale\n",
    "        _, binary1 = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Approach 2: Adaptive thresholding\n",
    "        binary2 = cv2.adaptiveThreshold(\n",
    "            enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV, 21, 5\n",
    "        )\n",
    "        \n",
    "        # Approach 3: Color-based (nuclei are typically darker/purple)\n",
    "        # Use saturation channel\n",
    "        sat = hsv[:, :, 1]\n",
    "        _, binary3 = cv2.threshold(sat, 30, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Combine approaches\n",
    "        binary = cv2.bitwise_and(binary1, binary2)\n",
    "        binary = cv2.bitwise_or(binary, binary3)\n",
    "        \n",
    "        # Morphological cleaning\n",
    "        kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        kernel_medium = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        \n",
    "        # Remove noise\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_small, iterations=2)\n",
    "        # Fill holes\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_medium, iterations=2)\n",
    "        \n",
    "        # Distance transform for watershed\n",
    "        dist_transform = cv2.distanceTransform(binary, cv2.DIST_L2, 5)\n",
    "        \n",
    "        # Normalize distance transform\n",
    "        if dist_transform.max() > 0:\n",
    "            dist_norm = dist_transform / dist_transform.max()\n",
    "        else:\n",
    "            # No foreground detected - return empty\n",
    "            return {'instance_map': np.zeros(image.shape[:2], dtype=np.int32), 'num_nuclei': 0}\n",
    "        \n",
    "        # Find sure foreground (peaks)\n",
    "        _, sure_fg = cv2.threshold(dist_transform, 0.3 * dist_transform.max(), 255, 0)\n",
    "        sure_fg = sure_fg.astype(np.uint8)\n",
    "        \n",
    "        # Sure background\n",
    "        sure_bg = cv2.dilate(binary, kernel_medium, iterations=3)\n",
    "        \n",
    "        # Unknown region\n",
    "        unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "        \n",
    "        # Connected components for markers\n",
    "        num_labels, markers = cv2.connectedComponents(sure_fg)\n",
    "        markers = markers + 1  # Background is 1, not 0\n",
    "        markers[unknown == 255] = 0  # Unknown regions are 0\n",
    "        \n",
    "        # Watershed\n",
    "        markers = cv2.watershed(image, markers)\n",
    "        \n",
    "        # Create instance map (remove boundaries marked as -1)\n",
    "        instance_map = np.zeros(image.shape[:2], dtype=np.int32)\n",
    "        instance_map[markers > 1] = markers[markers > 1] - 1  # Shift labels\n",
    "        \n",
    "        # Filter by size\n",
    "        min_area = 30\n",
    "        max_area = 10000\n",
    "        \n",
    "        unique_ids = np.unique(instance_map)\n",
    "        unique_ids = unique_ids[unique_ids > 0]\n",
    "        \n",
    "        valid_ids = []\n",
    "        for uid in unique_ids:\n",
    "            area = np.sum(instance_map == uid)\n",
    "            if min_area <= area <= max_area:\n",
    "                valid_ids.append(uid)\n",
    "            else:\n",
    "                instance_map[instance_map == uid] = 0\n",
    "        \n",
    "        # Relabel consecutively\n",
    "        final_map = np.zeros_like(instance_map)\n",
    "        for new_id, old_id in enumerate(valid_ids, start=1):\n",
    "            final_map[instance_map == old_id] = new_id\n",
    "        \n",
    "        num_nuclei = len(valid_ids)\n",
    "        \n",
    "        return {\n",
    "            'instance_map': final_map,\n",
    "            'num_nuclei': num_nuclei\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        if DEBUG_MODE:\n",
    "            print(f\"CV segmentation error: {e}\")\n",
    "            traceback.print_exc()\n",
    "        # Return empty result on error\n",
    "        return {\n",
    "            'instance_map': np.zeros(image.shape[:2], dtype=np.int32),\n",
    "            'num_nuclei': 0\n",
    "        }\n",
    "\n",
    "\n",
    "def segment_nuclei_hovernet(image):\n",
    "    \"\"\"\n",
    "    Segment nuclei using HoverNet model.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image (H, W, 3) uint8\n",
    "        \n",
    "    Returns:\n",
    "        dict with 'instance_map' and 'num_nuclei', or None if failed\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Preprocess\n",
    "        img = image.astype(np.float32) / 255.0\n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "        \n",
    "        # Extract predictions\n",
    "        if isinstance(output, dict):\n",
    "            pred_np = output.get('np', output.get('NP'))\n",
    "            pred_hv = output.get('hv', output.get('HV'))\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        if pred_np is None:\n",
    "            return None\n",
    "        \n",
    "        # Process NP prediction\n",
    "        pred_np = torch.softmax(pred_np, dim=1)[0, 1].cpu().numpy()\n",
    "        \n",
    "        # Binary mask\n",
    "        binary_mask = (pred_np > 0.5).astype(np.uint8)\n",
    "        \n",
    "        if pred_hv is not None:\n",
    "            pred_hv = pred_hv[0].permute(1, 2, 0).cpu().numpy()\n",
    "            # Use HV for watershed\n",
    "            h_grad = pred_hv[..., 0]\n",
    "            v_grad = pred_hv[..., 1]\n",
    "            \n",
    "            # Energy for watershed\n",
    "            grad_mag = np.sqrt(h_grad**2 + v_grad**2)\n",
    "            energy = pred_np * (1 - np.clip(grad_mag, 0, 1))\n",
    "        else:\n",
    "            energy = pred_np\n",
    "        \n",
    "        # Find markers using local maxima\n",
    "        from skimage.feature import peak_local_max\n",
    "        from skimage.segmentation import watershed\n",
    "        \n",
    "        coordinates = peak_local_max(\n",
    "            energy,\n",
    "            min_distance=5,\n",
    "            threshold_abs=0.1,\n",
    "            labels=binary_mask\n",
    "        )\n",
    "        \n",
    "        if len(coordinates) == 0:\n",
    "            instance_map, _ = scipy_label(binary_mask)\n",
    "        else:\n",
    "            markers = np.zeros_like(pred_np, dtype=np.int32)\n",
    "            for i, coord in enumerate(coordinates, start=1):\n",
    "                markers[coord[0], coord[1]] = i\n",
    "            instance_map = watershed(-energy, markers, mask=binary_mask)\n",
    "        \n",
    "        num_nuclei = len(np.unique(instance_map)) - 1\n",
    "        \n",
    "        return {\n",
    "            'instance_map': instance_map.astype(np.int32),\n",
    "            'num_nuclei': max(0, num_nuclei)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        if DEBUG_MODE:\n",
    "            print(f\"HoverNet inference error: {e}\")\n",
    "            traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "def segment_nuclei(image):\n",
    "    \"\"\"\n",
    "    Main segmentation function. Tries HoverNet first, falls back to CV.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image (H, W, 3) uint8\n",
    "        \n",
    "    Returns:\n",
    "        dict with 'instance_map' and 'num_nuclei'\n",
    "    \"\"\"\n",
    "    # Try HoverNet first\n",
    "    if model is not None:\n",
    "        result = segment_nuclei_hovernet(image)\n",
    "        if result is not None and result['num_nuclei'] > 0:\n",
    "            return result\n",
    "    \n",
    "    # Fallback to CV-based segmentation\n",
    "    return segment_nuclei_cv(image)\n",
    "\n",
    "\n",
    "print(\"✓ Segmentation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Segmentation on Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single image to verify segmentation works\n",
    "def test_single_image():\n",
    "    \"\"\"Test segmentation on a single image.\"\"\"\n",
    "    # Find a test image\n",
    "    test_class = CELL_CLASSES[0]\n",
    "    test_dir = os.path.join(DATASET_BASE_PATH, test_class, IMAGE_SUBFOLDER)\n",
    "    test_images = glob.glob(os.path.join(test_dir, '*.bmp'))\n",
    "    \n",
    "    if not test_images:\n",
    "        print(\"❌ No test images found\")\n",
    "        return False\n",
    "    \n",
    "    test_path = test_images[0]\n",
    "    print(f\"Testing on: {os.path.basename(test_path)}\")\n",
    "    \n",
    "    # Load image\n",
    "    img = cv2.imread(test_path)\n",
    "    if img is None:\n",
    "        print(f\"❌ Failed to load image\")\n",
    "        return False\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    print(f\"Image shape: {img_rgb.shape}\")\n",
    "    \n",
    "    # Run segmentation\n",
    "    print(\"Running segmentation...\")\n",
    "    result = segment_nuclei(img_rgb)\n",
    "    \n",
    "    print(f\"Nuclei detected: {result['num_nuclei']}\")\n",
    "    print(f\"Instance map shape: {result['instance_map'].shape}\")\n",
    "    print(f\"Unique labels: {np.unique(result['instance_map'])}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original\n",
    "    axes[0].imshow(img_rgb)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Instance map\n",
    "    axes[1].imshow(result['instance_map'], cmap='nipy_spectral')\n",
    "    axes[1].set_title(f'Instance Map ({result[\"num_nuclei\"]} nuclei)')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = img_rgb.copy()\n",
    "    mask = result['instance_map'] > 0\n",
    "    overlay[mask] = overlay[mask] * 0.5 + np.array([0, 255, 0]) * 0.5\n",
    "    axes[2].imshow(overlay.astype(np.uint8))\n",
    "    axes[2].set_title('Overlay')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return result['num_nuclei'] > 0\n",
    "\n",
    "\n",
    "# Run test\n",
    "if dataset_valid:\n",
    "    success = test_single_image()\n",
    "    if success:\n",
    "        print(\"\\n✓ Single image test PASSED\")\n",
    "    else:\n",
    "        print(\"\\n⚠ Single image test: No nuclei detected (may be normal for some images)\")\n",
    "else:\n",
    "    print(\"❌ Cannot test - dataset not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Image Processing and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"Load an image and convert to RGB.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load: {image_path}\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def create_overlay(image, mask, alpha=0.4):\n",
    "    \"\"\"Create colorful overlay of segmentation on image.\"\"\"\n",
    "    overlay = image.copy()\n",
    "    \n",
    "    unique_ids = np.unique(mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    if len(unique_ids) == 0:\n",
    "        return overlay\n",
    "    \n",
    "    # Generate colors\n",
    "    np.random.seed(42)\n",
    "    colors = np.random.randint(50, 255, size=(len(unique_ids), 3))\n",
    "    \n",
    "    colored_mask = np.zeros_like(image)\n",
    "    for idx, uid in enumerate(unique_ids):\n",
    "        colored_mask[mask == uid] = colors[idx]\n",
    "    \n",
    "    # Blend\n",
    "    overlay = cv2.addWeighted(image, 1 - alpha, colored_mask, alpha, 0)\n",
    "    \n",
    "    # Draw contours\n",
    "    for uid in unique_ids:\n",
    "        binary = (mask == uid).astype(np.uint8)\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(overlay, contours, -1, (255, 255, 0), 1)\n",
    "    \n",
    "    return overlay\n",
    "\n",
    "\n",
    "def save_results(output_dir, image_name, image, instance_map):\n",
    "    \"\"\"Save segmentation results.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(image_name)[0]\n",
    "    \n",
    "    # Save original\n",
    "    orig_path = os.path.join(output_dir, f\"{base_name}_original.png\")\n",
    "    cv2.imwrite(orig_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    # Save mask\n",
    "    mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")\n",
    "    cv2.imwrite(mask_path, instance_map.astype(np.uint16))\n",
    "    \n",
    "    # Save overlay\n",
    "    overlay = create_overlay(image, instance_map)\n",
    "    overlay_path = os.path.join(output_dir, f\"{base_name}_overlay.png\")\n",
    "    cv2.imwrite(overlay_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    return {'original': orig_path, 'mask': mask_path, 'overlay': overlay_path}\n",
    "\n",
    "\n",
    "print(\"✓ Image processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, output_dir):\n",
    "    \"\"\"Process a single image.\"\"\"\n",
    "    image_name = os.path.basename(image_path)\n",
    "    \n",
    "    try:\n",
    "        # Load\n",
    "        image = load_image(image_path)\n",
    "        \n",
    "        # Segment\n",
    "        result = segment_nuclei(image)\n",
    "        \n",
    "        # Save\n",
    "        saved = save_results(output_dir, image_name, image, result['instance_map'])\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'image_name': image_name,\n",
    "            'num_nuclei': result['num_nuclei'],\n",
    "            'saved_paths': saved,\n",
    "            'error': None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if DEBUG_MODE:\n",
    "            print(f\"\\n❌ Error processing {image_name}: {error_msg}\")\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            'success': False,\n",
    "            'image_name': image_name,\n",
    "            'num_nuclei': 0,\n",
    "            'saved_paths': None,\n",
    "            'error': error_msg\n",
    "        }\n",
    "\n",
    "\n",
    "def process_class(cell_class, max_images=None):\n",
    "    \"\"\"Process all images for a cell class.\"\"\"\n",
    "    input_dir = os.path.join(DATASET_BASE_PATH, cell_class, IMAGE_SUBFOLDER)\n",
    "    output_dir = os.path.join(OUTPUT_BASE_PATH, cell_class)\n",
    "    \n",
    "    images = sorted(glob.glob(os.path.join(input_dir, '*.bmp')))\n",
    "    if max_images:\n",
    "        images = images[:max_images]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {cell_class}\")\n",
    "    print(f\"Images: {len(images)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = []\n",
    "    errors = []\n",
    "    \n",
    "    for img_path in tqdm(images, desc=cell_class):\n",
    "        result = process_image(img_path, output_dir)\n",
    "        results.append(result)\n",
    "        if not result['success']:\n",
    "            errors.append(result)\n",
    "    \n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    total_nuclei = sum(r['num_nuclei'] for r in results if r['success'])\n",
    "    avg_nuclei = total_nuclei / successful if successful > 0 else 0\n",
    "    \n",
    "    print(f\"\\nSummary: {successful}/{len(images)} successful\")\n",
    "    print(f\"Total nuclei: {total_nuclei}, Avg: {avg_nuclei:.1f}\")\n",
    "    \n",
    "    if errors and DEBUG_MODE:\n",
    "        print(f\"\\nErrors ({len(errors)}):\")\n",
    "        for err in errors[:5]:  # Show first 5 errors\n",
    "            print(f\"  - {err['image_name']}: {err['error']}\")\n",
    "    \n",
    "    return {\n",
    "        'cell_class': cell_class,\n",
    "        'total_images': len(images),\n",
    "        'successful': successful,\n",
    "        'failed': len(images) - successful,\n",
    "        'total_nuclei': total_nuclei,\n",
    "        'avg_nuclei_per_image': avg_nuclei\n",
    "    }\n",
    "\n",
    "\n",
    "def process_all(max_images_per_class=None):\n",
    "    \"\"\"Process all cell classes.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING BATCH PROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    all_stats = {}\n",
    "    \n",
    "    for cell_class in CELL_CLASSES:\n",
    "        stats = process_class(cell_class, max_images_per_class)\n",
    "        all_stats[cell_class] = stats\n",
    "    \n",
    "    elapsed = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_images = sum(s['total_images'] for s in all_stats.values())\n",
    "    total_successful = sum(s['successful'] for s in all_stats.values())\n",
    "    total_nuclei = sum(s['total_nuclei'] for s in all_stats.values())\n",
    "    \n",
    "    overall = {\n",
    "        'processing_time_seconds': elapsed,\n",
    "        'total_images': total_images,\n",
    "        'total_successful': total_successful,\n",
    "        'total_failed': total_images - total_successful,\n",
    "        'total_nuclei_detected': total_nuclei,\n",
    "        'class_statistics': all_stats\n",
    "    }\n",
    "    \n",
    "    # Save statistics\n",
    "    stats_file = os.path.join(OUTPUT_BASE_PATH, 'processing_statistics.json')\n",
    "    with open(stats_file, 'w') as f:\n",
    "        json.dump(overall, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROCESSING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total: {total_images} images, {total_successful} successful\")\n",
    "    print(f\"Nuclei detected: {total_nuclei}\")\n",
    "    print(f\"Time: {elapsed:.1f}s ({elapsed/60:.1f} min)\")\n",
    "    print(f\"Stats saved: {stats_file}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return overall\n",
    "\n",
    "\n",
    "print(\"✓ Batch processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Run Processing\n",
    "\n",
    "### Test Run (5 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on first class with 5 images\n",
    "if dataset_valid:\n",
    "    print(\"Running test with 5 images...\\n\")\n",
    "    test_stats = process_class(CELL_CLASSES[0], max_images=5)\n",
    "    \n",
    "    if test_stats['successful'] > 0:\n",
    "        print(\"\\n✓ Test PASSED!\")\n",
    "    else:\n",
    "        print(\"\\n❌ Test FAILED - Check errors above\")\n",
    "else:\n",
    "    print(\"❌ Cannot run - check configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results from test\n",
    "def visualize_samples(cell_class, n=3):\n",
    "    \"\"\"Visualize sample results.\"\"\"\n",
    "    output_dir = os.path.join(OUTPUT_BASE_PATH, cell_class)\n",
    "    overlays = sorted(glob.glob(os.path.join(output_dir, '*_overlay.png')))\n",
    "    \n",
    "    if not overlays:\n",
    "        print(f\"No results for {cell_class}\")\n",
    "        return\n",
    "    \n",
    "    import random\n",
    "    samples = random.sample(overlays, min(n, len(overlays)))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(samples), figsize=(5*len(samples), 5))\n",
    "    if len(samples) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, path in enumerate(samples):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(cell_class.replace('im_', ''))\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Show test results\n",
    "if 'test_stats' in locals() and test_stats['successful'] > 0:\n",
    "    visualize_samples(CELL_CLASSES[0], n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process All Classes (50 images each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process 50 images per class\n",
    "if dataset_valid:\n",
    "    overall_stats = process_all(max_images_per_class=50)\n",
    "else:\n",
    "    print(\"❌ Cannot run - check configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process All Images (Full Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to process ALL images (may take a while)\n",
    "# if dataset_valid:\n",
    "#     overall_stats = process_all()\n",
    "# else:\n",
    "#     print(\"❌ Cannot run - check configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples from each class\n",
    "if 'overall_stats' in locals():\n",
    "    for cell_class in CELL_CLASSES:\n",
    "        print(f\"\\n{cell_class}:\")\n",
    "        visualize_samples(cell_class, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot statistics\n",
    "def plot_stats(stats):\n",
    "    \"\"\"Plot statistics.\"\"\"\n",
    "    class_stats = stats['class_statistics']\n",
    "    classes = list(class_stats.keys())\n",
    "    labels = [c.replace('im_', '') for c in classes]\n",
    "    \n",
    "    nuclei = [class_stats[c]['total_nuclei'] for c in classes]\n",
    "    avg = [class_stats[c]['avg_nuclei_per_image'] for c in classes]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    ax1.bar(range(len(classes)), nuclei, color='steelblue')\n",
    "    ax1.set_xticks(range(len(classes)))\n",
    "    ax1.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Total Nuclei')\n",
    "    ax1.set_title('Total Nuclei per Class')\n",
    "    \n",
    "    ax2.bar(range(len(classes)), avg, color='coral')\n",
    "    ax2.set_xticks(range(len(classes)))\n",
    "    ax2.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Avg Nuclei per Image')\n",
    "    ax2.set_title('Average Nuclei per Image')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if 'overall_stats' in locals():\n",
    "    plot_stats(overall_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean temp files\n",
    "if os.path.exists(TEMP_DIR):\n",
    "    shutil.rmtree(TEMP_DIR)\n",
    "    print(f\"✓ Cleaned: {TEMP_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Output Structure\n",
    "```\n",
    "HoverNet_Segmentation_Results/\n",
    "├── im_Dyskeratotic/\n",
    "│   ├── image_original.png\n",
    "│   ├── image_mask.png\n",
    "│   └── image_overlay.png\n",
    "├── im_Koilocytotic/\n",
    "├── im_Metaplastic/\n",
    "├── im_Parabasal/\n",
    "├── im_Superficial-Intermediate/\n",
    "└── processing_statistics.json\n",
    "```\n",
    "\n",
    "### Troubleshooting\n",
    "- Set `DEBUG_MODE = True` to see detailed error messages\n",
    "- CV-based segmentation is used if HoverNet model fails to load\n",
    "- Zero nuclei detected may be normal for some images\n",
    "\n",
    "### References\n",
    "- [HoverNet Paper](https://arxiv.org/abs/1812.06499)\n",
    "- [HoverNet GitHub](https://github.com/vqdang/hover_net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

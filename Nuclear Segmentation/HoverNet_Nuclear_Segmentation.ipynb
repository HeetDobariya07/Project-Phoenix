{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclear Segmentation using HoverNet\n",
    "\n",
    "This notebook implements nuclear segmentation for cervical cancer cell classification using the HoverNet model.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- Base Directory: `Augmented Dataset - Limited Enhancement`\n",
    "- Classes: `im_Dyskeratotic`, `im_Koilocytotic`, `im_Metaplastic`, `im_Parabasal`, `im_Superficial-Intermediate`\n",
    "- Images Location: `<class_folder>/NLM_CLAHE/*.bmp`\n",
    "\n",
    "**Reference:** [HoverNet GitHub](https://github.com/vqdang/hover_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "if IN_COLAB:\n",
    "    !pip install opencv-python-headless\n",
    "    !pip install scikit-image\n",
    "    !pip install scipy\n",
    "    !pip install matplotlib\n",
    "    !pip install tqdm\n",
    "    !pip install imageio\n",
    "    \n",
    "    # Install TensorFlow (HoverNet uses TensorFlow 1.x or 2.x)\n",
    "    !pip install tensorflow==2.12.0\n",
    "    \n",
    "    print(\"\\n✓ Dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone HoverNet repository\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    if not os.path.exists('hover_net'):\n",
    "        !git clone https://github.com/vqdang/hover_net.git\n",
    "        print(\"\\n✓ HoverNet repository cloned\")\n",
    "    else:\n",
    "        print(\"\\n✓ HoverNet repository already exists\")\n",
    "    \n",
    "    # Add HoverNet to Python path\n",
    "    import sys\n",
    "    sys.path.insert(0, '/content/hover_net')\n",
    "    print(\"✓ HoverNet added to Python path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"\\n✓ Google Drive mounted successfully\")\n",
    "else:\n",
    "    print(\"Skipping Google Drive mount (not on Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(\"\\n✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration and Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dataset paths\n",
    "# IMPORTANT: Update this path to match your Google Drive structure\n",
    "DRIVE_BASE_PATH = '/content/drive/MyDrive'  # Default Google Drive path\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = 'Augmented Dataset - Limited Enhancement'\n",
    "DATASET_BASE_PATH = os.path.join(DRIVE_BASE_PATH, DATASET_NAME)\n",
    "\n",
    "# Cell classes\n",
    "CELL_CLASSES = [\n",
    "    'im_Dyskeratotic',\n",
    "    'im_Koilocytotic',\n",
    "    'im_Metaplastic',\n",
    "    'im_Parabasal',\n",
    "    'im_Superficial-Intermediate'\n",
    "]\n",
    "\n",
    "# Subfolder containing images\n",
    "IMAGE_SUBFOLDER = 'NLM_CLAHE'\n",
    "\n",
    "# Output directory for segmentation results\n",
    "OUTPUT_BASE_PATH = os.path.join(DRIVE_BASE_PATH, 'HoverNet_Segmentation_Results')\n",
    "os.makedirs(OUTPUT_BASE_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset base path: {DATASET_BASE_PATH}\")\n",
    "print(f\"Output base path: {OUTPUT_BASE_PATH}\")\n",
    "print(f\"\\nCell classes to process: {len(CELL_CLASSES)}\")\n",
    "for i, cell_class in enumerate(CELL_CLASSES, 1):\n",
    "    print(f\"  {i}. {cell_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset exists and count images\n",
    "def verify_dataset():\n",
    "    \"\"\"Verify dataset structure and count images per class.\"\"\"\n",
    "    print(\"Verifying dataset structure...\\n\")\n",
    "    \n",
    "    if not os.path.exists(DATASET_BASE_PATH):\n",
    "        print(f\"❌ ERROR: Dataset base path not found: {DATASET_BASE_PATH}\")\n",
    "        print(\"\\nPlease update DRIVE_BASE_PATH and DATASET_NAME in the previous cell.\")\n",
    "        return False\n",
    "    \n",
    "    total_images = 0\n",
    "    class_image_counts = {}\n",
    "    \n",
    "    for cell_class in CELL_CLASSES:\n",
    "        class_path = os.path.join(DATASET_BASE_PATH, cell_class)\n",
    "        image_path = os.path.join(class_path, IMAGE_SUBFOLDER)\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"❌ WARNING: Image path not found: {image_path}\")\n",
    "            class_image_counts[cell_class] = 0\n",
    "            continue\n",
    "        \n",
    "        # Count .bmp files\n",
    "        bmp_files = glob.glob(os.path.join(image_path, '*.bmp'))\n",
    "        count = len(bmp_files)\n",
    "        class_image_counts[cell_class] = count\n",
    "        total_images += count\n",
    "        \n",
    "        print(f\"✓ {cell_class}: {count} images\")\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Total images to process: {total_images}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    return total_images > 0, class_image_counts\n",
    "\n",
    "# Run verification\n",
    "dataset_valid, image_counts = verify_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download HoverNet Pre-trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-trained weights for HoverNet\n",
    "# The original repository provides pre-trained weights\n",
    "\n",
    "WEIGHTS_DIR = '/content/hover_net_weights'\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Downloading HoverNet pre-trained weights...\")\n",
    "print(\"\\nNote: HoverNet provides multiple pre-trained models:\")\n",
    "print(\"  - CoNSeP dataset model\")\n",
    "print(\"  - Kumar dataset model\")\n",
    "print(\"  - CPM dataset model\")\n",
    "print(\"\\nFor cervical cancer cells, you may need to fine-tune or use the general model.\")\n",
    "print(\"\\nPlease download weights from: https://github.com/vqdang/hover_net#data-format\")\n",
    "print(f\"And place them in: {WEIGHTS_DIR}\")\n",
    "print(\"\\nAlternatively, you can use the model checkpoint directly from the repository.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. HoverNet Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HoverNet modules\n",
    "try:\n",
    "    # These imports depend on the HoverNet repository structure\n",
    "    # Adjust if the repository structure changes\n",
    "    from hover_net.infer.tile import InferManager\n",
    "    from hover_net.config import Config\n",
    "    print(\"✓ HoverNet modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠ Import warning: {e}\")\n",
    "    print(\"\\nNote: HoverNet may require manual configuration.\")\n",
    "    print(\"Please check the repository structure and adjust imports accordingly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use HoverNet inference script directly\n",
    "# This approach uses the command-line interface\n",
    "\n",
    "def setup_hovernet_config():\n",
    "    \"\"\"\n",
    "    Setup HoverNet configuration for inference.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        'model_path': os.path.join(WEIGHTS_DIR, 'hovernet_original_consep_notype_tf2pytorch.tar'),\n",
    "        'nr_inference_workers': 4,\n",
    "        'nr_post_proc_workers': 4,\n",
    "        'batch_size': 8,\n",
    "        'input_shape': [256, 256],  # HoverNet default input size\n",
    "        'output_types': ['instance', 'type'],  # Segment nuclei instances and types\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "config = setup_hovernet_config()\n",
    "print(\"HoverNet configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Image Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load a .bmp image and convert to RGB.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: RGB image\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "def preprocess_for_hovernet(image):\n",
    "    \"\"\"\n",
    "    Preprocess image for HoverNet inference.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image array\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed image\n",
    "    \"\"\"\n",
    "    # HoverNet expects images in RGB format with values in [0, 255]\n",
    "    # Ensure image is in the correct format\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def save_segmentation_result(output_dir, image_name, original_image, segmentation_mask):\n",
    "    \"\"\"\n",
    "    Save segmentation results including original image, mask, and overlay.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save results\n",
    "        image_name: Name of the original image\n",
    "        original_image: Original RGB image\n",
    "        segmentation_mask: Segmentation mask from HoverNet\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    base_name = os.path.splitext(image_name)[0]\n",
    "    \n",
    "    # Save original image\n",
    "    original_path = os.path.join(output_dir, f\"{base_name}_original.png\")\n",
    "    cv2.imwrite(original_path, cv2.cvtColor(original_image, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    # Save segmentation mask\n",
    "    mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")\n",
    "    cv2.imwrite(mask_path, segmentation_mask.astype(np.uint16))\n",
    "    \n",
    "    # Create and save overlay\n",
    "    overlay = create_overlay(original_image, segmentation_mask)\n",
    "    overlay_path = os.path.join(output_dir, f\"{base_name}_overlay.png\")\n",
    "    cv2.imwrite(overlay_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    return {\n",
    "        'original': original_path,\n",
    "        'mask': mask_path,\n",
    "        'overlay': overlay_path\n",
    "    }\n",
    "\n",
    "\n",
    "def create_overlay(image, mask, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Create an overlay of the segmentation mask on the original image.\n",
    "    \n",
    "    Args:\n",
    "        image: Original RGB image\n",
    "        mask: Segmentation mask\n",
    "        alpha: Transparency factor\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Overlay image\n",
    "    \"\"\"\n",
    "    # Create a colorized version of the mask\n",
    "    colored_mask = np.zeros_like(image)\n",
    "    \n",
    "    # Assign different colors to different nuclei instances\n",
    "    unique_instances = np.unique(mask)\n",
    "    np.random.seed(42)  # For reproducible colors\n",
    "    \n",
    "    for instance_id in unique_instances:\n",
    "        if instance_id == 0:  # Skip background\n",
    "            continue\n",
    "        color = np.random.randint(0, 255, size=3)\n",
    "        colored_mask[mask == instance_id] = color\n",
    "    \n",
    "    # Blend original image with colored mask\n",
    "    overlay = cv2.addWeighted(image, 1-alpha, colored_mask, alpha, 0)\n",
    "    \n",
    "    return overlay\n",
    "\n",
    "print(\"✓ Image processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. HoverNet Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hovernet_inference(image):\n",
    "    \"\"\"\n",
    "    Run HoverNet inference on a single image.\n",
    "    \n",
    "    This is a placeholder function. The actual implementation depends on\n",
    "    how you set up HoverNet (using the Python API or command-line interface).\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image array\n",
    "        \n",
    "    Returns:\n",
    "        dict: Segmentation results containing:\n",
    "            - 'instance_map': Instance segmentation map\n",
    "            - 'type_map': Cell type classification map (if available)\n",
    "            - 'contours': List of nucleus contours\n",
    "    \"\"\"\n",
    "    # TODO: Implement actual HoverNet inference\n",
    "    # This will depend on the HoverNet setup\n",
    "    \n",
    "    # Option 1: Use HoverNet Python API\n",
    "    # result = infer_manager.run_inference(image)\n",
    "    \n",
    "    # Option 2: Use command-line interface\n",
    "    # Save image temporarily, run inference, load results\n",
    "    \n",
    "    # For now, return a placeholder\n",
    "    print(\"⚠ Warning: Using placeholder inference. Implement actual HoverNet inference.\")\n",
    "    \n",
    "    # Placeholder: Simple thresholding as example\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create instance map\n",
    "    instance_map = np.zeros(image.shape[:2], dtype=np.uint16)\n",
    "    for idx, contour in enumerate(contours, start=1):\n",
    "        cv2.drawContours(instance_map, [contour], -1, idx, -1)\n",
    "    \n",
    "    return {\n",
    "        'instance_map': instance_map,\n",
    "        'type_map': None,\n",
    "        'contours': contours,\n",
    "        'num_nuclei': len(contours)\n",
    "    }\n",
    "\n",
    "print(\"✓ HoverNet inference function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Batch Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single image through the HoverNet pipeline.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to input image\n",
    "        output_dir: Directory to save results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing results and statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load image\n",
    "        image = load_image(image_path)\n",
    "        \n",
    "        # Preprocess\n",
    "        preprocessed = preprocess_for_hovernet(image)\n",
    "        \n",
    "        # Run HoverNet inference\n",
    "        results = run_hovernet_inference(preprocessed)\n",
    "        \n",
    "        # Save results\n",
    "        image_name = os.path.basename(image_path)\n",
    "        saved_paths = save_segmentation_result(\n",
    "            output_dir,\n",
    "            image_name,\n",
    "            image,\n",
    "            results['instance_map']\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'image_path': image_path,\n",
    "            'num_nuclei': results['num_nuclei'],\n",
    "            'saved_paths': saved_paths,\n",
    "            'error': None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'image_path': image_path,\n",
    "            'num_nuclei': 0,\n",
    "            'saved_paths': None,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "def process_cell_class(cell_class, progress_bar=True):\n",
    "    \"\"\"\n",
    "    Process all images for a specific cell class.\n",
    "    \n",
    "    Args:\n",
    "        cell_class: Name of the cell class\n",
    "        progress_bar: Whether to show progress bar\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing statistics\n",
    "    \"\"\"\n",
    "    # Setup paths\n",
    "    input_dir = os.path.join(DATASET_BASE_PATH, cell_class, IMAGE_SUBFOLDER)\n",
    "    output_dir = os.path.join(OUTPUT_BASE_PATH, cell_class)\n",
    "    \n",
    "    # Get all .bmp files\n",
    "    image_files = glob.glob(os.path.join(input_dir, '*.bmp'))\n",
    "    \n",
    "    print(f\"\\nProcessing {cell_class}: {len(image_files)} images\")\n",
    "    print(f\"Output directory: {output_dir}\\n\")\n",
    "    \n",
    "    # Process each image\n",
    "    results = []\n",
    "    iterator = tqdm(image_files) if progress_bar else image_files\n",
    "    \n",
    "    for image_path in iterator:\n",
    "        result = process_single_image(image_path, output_dir)\n",
    "        results.append(result)\n",
    "        \n",
    "        if not result['success']:\n",
    "            print(f\"\\n❌ Error processing {os.path.basename(image_path)}: {result['error']}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    failed = len(results) - successful\n",
    "    total_nuclei = sum(r['num_nuclei'] for r in results if r['success'])\n",
    "    avg_nuclei = total_nuclei / successful if successful > 0 else 0\n",
    "    \n",
    "    stats = {\n",
    "        'cell_class': cell_class,\n",
    "        'total_images': len(image_files),\n",
    "        'successful': successful,\n",
    "        'failed': failed,\n",
    "        'total_nuclei': total_nuclei,\n",
    "        'avg_nuclei_per_image': avg_nuclei,\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def process_all_classes():\n",
    "    \"\"\"\n",
    "    Process all cell classes in the dataset.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Complete processing statistics\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"Starting batch processing of all cell classes\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    all_stats = {}\n",
    "    \n",
    "    for cell_class in CELL_CLASSES:\n",
    "        stats = process_cell_class(cell_class)\n",
    "        all_stats[cell_class] = stats\n",
    "        \n",
    "        # Print summary for this class\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Summary for {cell_class}:\")\n",
    "        print(f\"  Total images: {stats['total_images']}\")\n",
    "        print(f\"  Successful: {stats['successful']}\")\n",
    "        print(f\"  Failed: {stats['failed']}\")\n",
    "        print(f\"  Total nuclei detected: {stats['total_nuclei']}\")\n",
    "        print(f\"  Average nuclei per image: {stats['avg_nuclei_per_image']:.2f}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    processing_time = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_images = sum(stats['total_images'] for stats in all_stats.values())\n",
    "    total_successful = sum(stats['successful'] for stats in all_stats.values())\n",
    "    total_failed = sum(stats['failed'] for stats in all_stats.values())\n",
    "    total_nuclei = sum(stats['total_nuclei'] for stats in all_stats.values())\n",
    "    \n",
    "    overall_stats = {\n",
    "        'start_time': start_time.isoformat(),\n",
    "        'end_time': end_time.isoformat(),\n",
    "        'processing_time_seconds': processing_time,\n",
    "        'total_images': total_images,\n",
    "        'total_successful': total_successful,\n",
    "        'total_failed': total_failed,\n",
    "        'total_nuclei_detected': total_nuclei,\n",
    "        'class_statistics': all_stats\n",
    "    }\n",
    "    \n",
    "    # Save overall statistics\n",
    "    stats_file = os.path.join(OUTPUT_BASE_PATH, 'processing_statistics.json')\n",
    "    with open(stats_file, 'w') as f:\n",
    "        json.dump(overall_stats, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OVERALL PROCESSING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Successful: {total_successful}\")\n",
    "    print(f\"Failed: {total_failed}\")\n",
    "    print(f\"Total nuclei detected: {total_nuclei}\")\n",
    "    print(f\"Processing time: {processing_time:.2f} seconds ({processing_time/60:.2f} minutes)\")\n",
    "    print(f\"Statistics saved to: {stats_file}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return overall_stats\n",
    "\n",
    "print(\"✓ Batch processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_results(cell_class, num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualize sample segmentation results for a cell class.\n",
    "    \n",
    "    Args:\n",
    "        cell_class: Name of the cell class\n",
    "        num_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    output_dir = os.path.join(OUTPUT_BASE_PATH, cell_class)\n",
    "    \n",
    "    # Get sample overlay images\n",
    "    overlay_files = glob.glob(os.path.join(output_dir, '*_overlay.png'))\n",
    "    \n",
    "    if not overlay_files:\n",
    "        print(f\"No results found for {cell_class}\")\n",
    "        return\n",
    "    \n",
    "    # Select random samples\n",
    "    import random\n",
    "    samples = random.sample(overlay_files, min(num_samples, len(overlay_files)))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, len(samples), figsize=(15, 5))\n",
    "    if len(samples) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, overlay_path in enumerate(samples):\n",
    "        overlay = cv2.imread(overlay_path)\n",
    "        overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[idx].imshow(overlay_rgb)\n",
    "        axes[idx].set_title(f\"{cell_class}\\n{os.path.basename(overlay_path)}\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_statistics(stats):\n",
    "    \"\"\"\n",
    "    Plot processing statistics across all cell classes.\n",
    "    \n",
    "    Args:\n",
    "        stats: Overall statistics dictionary\n",
    "    \"\"\"\n",
    "    class_stats = stats['class_statistics']\n",
    "    \n",
    "    cell_classes = list(class_stats.keys())\n",
    "    nuclei_counts = [class_stats[c]['total_nuclei'] for c in cell_classes]\n",
    "    avg_nuclei = [class_stats[c]['avg_nuclei_per_image'] for c in cell_classes]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Total nuclei per class\n",
    "    ax1.bar(range(len(cell_classes)), nuclei_counts)\n",
    "    ax1.set_xlabel('Cell Class')\n",
    "    ax1.set_ylabel('Total Nuclei Detected')\n",
    "    ax1.set_title('Total Nuclei Detected per Cell Class')\n",
    "    ax1.set_xticks(range(len(cell_classes)))\n",
    "    ax1.set_xticklabels([c.replace('im_', '') for c in cell_classes], rotation=45, ha='right')\n",
    "    \n",
    "    # Plot 2: Average nuclei per image\n",
    "    ax2.bar(range(len(cell_classes)), avg_nuclei)\n",
    "    ax2.set_xlabel('Cell Class')\n",
    "    ax2.set_ylabel('Average Nuclei per Image')\n",
    "    ax2.set_title('Average Nuclei per Image by Cell Class')\n",
    "    ax2.set_xticks(range(len(cell_classes)))\n",
    "    ax2.set_xticklabels([c.replace('im_', '') for c in cell_classes], rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"✓ Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Run Processing\n",
    "\n",
    "**⚠️ IMPORTANT:** Before running this cell, make sure:\n",
    "1. HoverNet repository is cloned\n",
    "2. Pre-trained weights are downloaded\n",
    "3. `run_hovernet_inference()` function is properly implemented\n",
    "4. Dataset paths are correctly configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images\n",
    "if dataset_valid:\n",
    "    # Run batch processing\n",
    "    overall_stats = process_all_classes()\n",
    "else:\n",
    "    print(\"❌ Dataset validation failed. Please check your dataset paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample results for each class\n",
    "for cell_class in CELL_CLASSES:\n",
    "    print(f\"\\nSample results for {cell_class}:\")\n",
    "    visualize_sample_results(cell_class, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overall statistics\n",
    "if 'overall_stats' in locals():\n",
    "    plot_statistics(overall_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Export Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary report\n",
    "def create_summary_report(stats):\n",
    "    \"\"\"\n",
    "    Create a formatted summary report of the processing results.\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(\"HoverNet Nuclear Segmentation - Processing Report\")\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(f\"\\nProcessing Date: {stats['start_time']}\")\n",
    "    report.append(f\"Total Processing Time: {stats['processing_time_seconds']:.2f} seconds\")\n",
    "    report.append(f\"\\nDataset: {DATASET_NAME}\")\n",
    "    report.append(f\"Output Location: {OUTPUT_BASE_PATH}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"OVERALL STATISTICS\")\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(f\"Total Images Processed: {stats['total_images']}\")\n",
    "    report.append(f\"Successful: {stats['total_successful']}\")\n",
    "    report.append(f\"Failed: {stats['total_failed']}\")\n",
    "    report.append(f\"Total Nuclei Detected: {stats['total_nuclei_detected']}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"PER-CLASS STATISTICS\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    for cell_class, class_stats in stats['class_statistics'].items():\n",
    "        report.append(f\"\\n{cell_class}:\")\n",
    "        report.append(f\"  Images: {class_stats['total_images']}\")\n",
    "        report.append(f\"  Successful: {class_stats['successful']}\")\n",
    "        report.append(f\"  Failed: {class_stats['failed']}\")\n",
    "        report.append(f\"  Total Nuclei: {class_stats['total_nuclei']}\")\n",
    "        report.append(f\"  Avg Nuclei/Image: {class_stats['avg_nuclei_per_image']:.2f}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "\n",
    "if 'overall_stats' in locals():\n",
    "    # Generate and save report\n",
    "    report = create_summary_report(overall_stats)\n",
    "    \n",
    "    # Print report\n",
    "    print(report)\n",
    "    \n",
    "    # Save report to file\n",
    "    report_file = os.path.join(OUTPUT_BASE_PATH, 'processing_report.txt')\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(f\"\\n✓ Report saved to: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Additional Notes and Next Steps\n",
    "\n",
    "### Important Implementation Notes:\n",
    "\n",
    "1. **HoverNet Setup:** The `run_hovernet_inference()` function currently contains placeholder code. You need to implement the actual HoverNet inference based on how you configure the model.\n",
    "\n",
    "2. **Model Weights:** Download the appropriate pre-trained weights from the HoverNet repository and update the `WEIGHTS_DIR` path.\n",
    "\n",
    "3. **Memory Management:** For large datasets, consider processing images in batches and clearing memory periodically.\n",
    "\n",
    "4. **GPU Acceleration:** If available, configure TensorFlow to use GPU for faster processing.\n",
    "\n",
    "### Recommended Next Steps:\n",
    "\n",
    "1. **Model Evaluation:** Validate segmentation quality on a subset of images\n",
    "2. **Fine-tuning:** Consider fine-tuning HoverNet on cervical cell images if needed\n",
    "3. **Feature Extraction:** Extract morphological features from segmented nuclei\n",
    "4. **Integration:** Integrate segmentation results with your classification pipeline\n",
    "\n",
    "### References:\n",
    "\n",
    "- HoverNet Paper: https://arxiv.org/abs/1812.06499\n",
    "- HoverNet Repository: https://github.com/vqdang/hover_net\n",
    "- Documentation: Check the repository README for detailed usage instructions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

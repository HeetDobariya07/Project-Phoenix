{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclear Segmentation using HoverNet\n",
    "\n",
    "This notebook implements nuclear segmentation for cervical cancer cell classification using the HoverNet model.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- Base Directory: `Augmented Dataset - Limited Enhancement`\n",
    "- Classes: `im_Dyskeratotic`, `im_Koilocytotic`, `im_Metaplastic`, `im_Parabasal`, `im_Superficial-Intermediate`\n",
    "- Images Location: `<class_folder>/NLM_CLAHE/*.bmp`\n",
    "\n",
    "**Reference:** [HoverNet GitHub](https://github.com/vqdang/hover_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"✓ Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"ℹ Not running on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "if IN_COLAB:\n",
    "    print(\"Installing dependencies...\\n\")\n",
    "    \n",
    "    # Core dependencies\n",
    "    !pip install -q opencv-python-headless\n",
    "    !pip install -q scikit-image\n",
    "    !pip install -q scipy\n",
    "    !pip install -q matplotlib\n",
    "    !pip install -q tqdm\n",
    "    !pip install -q pillow\n",
    "    \n",
    "    # PyTorch (HoverNet uses PyTorch)\n",
    "    !pip install -q torch torchvision\n",
    "    \n",
    "    # Additional dependencies for HoverNet\n",
    "    !pip install -q imgaug\n",
    "    !pip install -q termcolor\n",
    "    \n",
    "    print(\"\\n✓ Dependencies installed successfully\")\n",
    "else:\n",
    "    print(\"Skipping dependency installation (not on Colab)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone HoverNet repository\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if IN_COLAB:\n",
    "    HOVERNET_DIR = '/content/hover_net'\n",
    "    \n",
    "    if not os.path.exists(HOVERNET_DIR):\n",
    "        print(\"Cloning HoverNet repository...\")\n",
    "        !git clone https://github.com/vqdang/hover_net.git {HOVERNET_DIR}\n",
    "        print(\"✓ HoverNet repository cloned\")\n",
    "    else:\n",
    "        print(\"✓ HoverNet repository already exists\")\n",
    "    \n",
    "    # Add HoverNet to Python path\n",
    "    if HOVERNET_DIR not in sys.path:\n",
    "        sys.path.insert(0, HOVERNET_DIR)\n",
    "    print(\"✓ HoverNet added to Python path\")\n",
    "else:\n",
    "    HOVERNET_DIR = './hover_net'\n",
    "    print(\"Skipping HoverNet clone (not on Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"\\n✓ Google Drive mounted successfully\")\n",
    "else:\n",
    "    print(\"Skipping Google Drive mount (not on Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(f\"✓ Using device: {DEVICE}\")\n",
    "\n",
    "print(f\"✓ OpenCV version: {cv2.__version__}\")\n",
    "print(f\"✓ NumPy version: {np.__version__}\")\n",
    "print(\"\\n✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - UPDATE THESE PATHS AS NEEDED\n",
    "# ============================================================================\n",
    "\n",
    "# Google Drive base path\n",
    "DRIVE_BASE_PATH = '/content/drive/MyDrive'\n",
    "\n",
    "# HoverNet weights directory (contains the .tar file)\n",
    "WEIGHTS_DIR = '/content/drive/MyDrive/Projects/6_Project Phoenix_Cervical Cancer Cell Classification/Explainability Worflows/Nucleus Masking/Hovernet Weights'\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = 'Augmented Dataset - Limited Enhancement'\n",
    "DATASET_BASE_PATH = os.path.join(DRIVE_BASE_PATH, DATASET_NAME)\n",
    "\n",
    "# Cell classes\n",
    "CELL_CLASSES = [\n",
    "    'im_Dyskeratotic',\n",
    "    'im_Koilocytotic',\n",
    "    'im_Metaplastic',\n",
    "    'im_Parabasal',\n",
    "    'im_Superficial-Intermediate'\n",
    "]\n",
    "\n",
    "# Subfolder containing images\n",
    "IMAGE_SUBFOLDER = 'NLM_CLAHE'\n",
    "\n",
    "# Output directory for segmentation results\n",
    "OUTPUT_BASE_PATH = os.path.join(DRIVE_BASE_PATH, 'HoverNet_Segmentation_Results')\n",
    "os.makedirs(OUTPUT_BASE_PATH, exist_ok=True)\n",
    "\n",
    "# Temporary directory for processing\n",
    "TEMP_DIR = '/content/temp_hovernet'\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Weights directory: {WEIGHTS_DIR}\")\n",
    "print(f\"Dataset base path: {DATASET_BASE_PATH}\")\n",
    "print(f\"Output base path: {OUTPUT_BASE_PATH}\")\n",
    "print(f\"HoverNet directory: {HOVERNET_DIR}\")\n",
    "print(f\"\\nCell classes to process: {len(CELL_CLASSES)}\")\n",
    "for i, cell_class in enumerate(CELL_CLASSES, 1):\n",
    "    print(f\"  {i}. {cell_class}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Weights and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weight_file():\n",
    "    \"\"\"\n",
    "    Find the HoverNet weight file (.tar) in the weights directory.\n",
    "    \"\"\"\n",
    "    print(\"Searching for HoverNet weights...\\n\")\n",
    "    \n",
    "    if not os.path.exists(WEIGHTS_DIR):\n",
    "        print(f\"❌ ERROR: Weights directory not found: {WEIGHTS_DIR}\")\n",
    "        return None\n",
    "    \n",
    "    # List all files\n",
    "    all_files = os.listdir(WEIGHTS_DIR)\n",
    "    print(f\"Files in weights directory:\")\n",
    "    for f in all_files:\n",
    "        file_path = os.path.join(WEIGHTS_DIR, f)\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"  - {f} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Find .tar files (HoverNet PyTorch weights)\n",
    "    tar_files = [f for f in all_files if f.endswith('.tar')]\n",
    "    \n",
    "    if not tar_files:\n",
    "        print(\"\\n❌ ERROR: No .tar weight files found!\")\n",
    "        print(\"Please download HoverNet weights from:\")\n",
    "        print(\"https://github.com/vqdang/hover_net#data-format\")\n",
    "        return None\n",
    "    \n",
    "    # Use the first .tar file found\n",
    "    weight_file = os.path.join(WEIGHTS_DIR, tar_files[0])\n",
    "    print(f\"\\n✓ Found weight file: {tar_files[0]}\")\n",
    "    \n",
    "    return weight_file\n",
    "\n",
    "\n",
    "def verify_dataset():\n",
    "    \"\"\"\n",
    "    Verify dataset structure and count images.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Verifying dataset...\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    if not os.path.exists(DATASET_BASE_PATH):\n",
    "        print(f\"❌ ERROR: Dataset not found: {DATASET_BASE_PATH}\")\n",
    "        return False, {}\n",
    "    \n",
    "    total_images = 0\n",
    "    class_counts = {}\n",
    "    \n",
    "    for cell_class in CELL_CLASSES:\n",
    "        image_dir = os.path.join(DATASET_BASE_PATH, cell_class, IMAGE_SUBFOLDER)\n",
    "        \n",
    "        if not os.path.exists(image_dir):\n",
    "            print(f\"❌ {cell_class}: Directory not found\")\n",
    "            class_counts[cell_class] = 0\n",
    "            continue\n",
    "        \n",
    "        images = glob.glob(os.path.join(image_dir, '*.bmp'))\n",
    "        count = len(images)\n",
    "        class_counts[cell_class] = count\n",
    "        total_images += count\n",
    "        print(f\"✓ {cell_class:40s}: {count:5d} images\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Total images: {total_images}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    return total_images > 0, class_counts\n",
    "\n",
    "\n",
    "# Run verifications\n",
    "WEIGHT_FILE = find_weight_file()\n",
    "dataset_valid, image_counts = verify_dataset()\n",
    "\n",
    "if WEIGHT_FILE and dataset_valid:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✓ ALL VERIFICATIONS PASSED\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"❌ VERIFICATION FAILED - Please fix errors above\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load HoverNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HoverNet model components\n",
    "try:\n",
    "    from hover_net.models.hovernet.net_desc import create_model\n",
    "    from hover_net.models.hovernet.post_proc import process\n",
    "    print(\"✓ HoverNet modules imported successfully\")\n",
    "    HOVERNET_MODULES_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"⚠ Could not import HoverNet modules: {e}\")\n",
    "    print(\"Will use alternative inference method\")\n",
    "    HOVERNET_MODULES_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hovernet_model(weight_path):\n",
    "    \"\"\"\n",
    "    Load HoverNet model from .tar checkpoint file.\n",
    "    \n",
    "    Args:\n",
    "        weight_path: Path to the .tar weight file\n",
    "        \n",
    "    Returns:\n",
    "        model: Loaded PyTorch model\n",
    "        model_config: Model configuration dict\n",
    "    \"\"\"\n",
    "    print(f\"\\nLoading HoverNet model from: {weight_path}\")\n",
    "    print(\"This may take a moment...\\n\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(weight_path, map_location=DEVICE)\n",
    "    \n",
    "    # Print checkpoint contents\n",
    "    print(f\"Checkpoint keys: {list(checkpoint.keys())}\")\n",
    "    \n",
    "    # Get model configuration\n",
    "    if 'desc' in checkpoint:\n",
    "        model_config = checkpoint['desc']\n",
    "        print(f\"Model description: {model_config}\")\n",
    "    else:\n",
    "        model_config = None\n",
    "    \n",
    "    # Determine number of types from checkpoint\n",
    "    nr_types = 0  # Default: no type classification\n",
    "    if model_config:\n",
    "        # Try to extract nr_types from model description\n",
    "        if isinstance(model_config, dict) and 'nr_types' in model_config:\n",
    "            nr_types = model_config['nr_types']\n",
    "    \n",
    "    # Check state dict for type head\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint.get('model_state_dict', checkpoint))\n",
    "    \n",
    "    # Look for type prediction layers to determine nr_types\n",
    "    for key in state_dict.keys():\n",
    "        if 'tp' in key.lower() or 'type' in key.lower():\n",
    "            print(f\"Found type-related key: {key}\")\n",
    "            if 'tp.u0.conv.weight' in key:\n",
    "                # Extract nr_types from output channels\n",
    "                nr_types = state_dict[key].shape[0]\n",
    "                print(f\"Detected nr_types from weights: {nr_types}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nModel configuration:\")\n",
    "    print(f\"  - Number of types: {nr_types}\")\n",
    "    print(f\"  - Device: {DEVICE}\")\n",
    "    \n",
    "    # Create model\n",
    "    if HOVERNET_MODULES_AVAILABLE:\n",
    "        try:\n",
    "            model = create_model(\n",
    "                mode='fast',  # or 'original'\n",
    "                nr_types=nr_types if nr_types > 0 else None\n",
    "            )\n",
    "            \n",
    "            # Load state dict\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "            model = model.to(DEVICE)\n",
    "            model.eval()\n",
    "            \n",
    "            print(\"\\n✓ HoverNet model loaded successfully!\")\n",
    "            return model, {'nr_types': nr_types}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Error creating model: {e}\")\n",
    "            print(\"Will use alternative method\")\n",
    "    \n",
    "    # Return checkpoint for alternative processing\n",
    "    return checkpoint, {'nr_types': nr_types, 'state_dict': state_dict}\n",
    "\n",
    "\n",
    "# Load the model\n",
    "if WEIGHT_FILE:\n",
    "    model, model_config = load_hovernet_model(WEIGHT_FILE)\n",
    "else:\n",
    "    model = None\n",
    "    model_config = None\n",
    "    print(\"❌ Cannot load model - weight file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label as scipy_label\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess image for HoverNet inference.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image (H, W, 3) uint8\n",
    "        \n",
    "    Returns:\n",
    "        tensor: Preprocessed image tensor\n",
    "    \"\"\"\n",
    "    # Normalize to [0, 1]\n",
    "    img = image.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Convert to tensor (N, C, H, W)\n",
    "    img_tensor = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0)\n",
    "    \n",
    "    return img_tensor.to(DEVICE)\n",
    "\n",
    "\n",
    "def post_process_nuclei(pred_np, pred_hv):\n",
    "    \"\"\"\n",
    "    Post-process HoverNet predictions to get instance segmentation.\n",
    "    \n",
    "    Args:\n",
    "        pred_np: Nuclear pixel prediction (H, W)\n",
    "        pred_hv: Horizontal-Vertical gradient prediction (H, W, 2)\n",
    "        \n",
    "    Returns:\n",
    "        instance_map: Instance segmentation map (H, W)\n",
    "    \"\"\"\n",
    "    # Threshold nuclear prediction\n",
    "    pred_np_binary = pred_np > 0.5\n",
    "    \n",
    "    if not np.any(pred_np_binary):\n",
    "        return np.zeros_like(pred_np, dtype=np.int32)\n",
    "    \n",
    "    # Use HV gradients to separate touching nuclei\n",
    "    h_grad = pred_hv[..., 0]\n",
    "    v_grad = pred_hv[..., 1]\n",
    "    \n",
    "    # Compute gradient magnitude\n",
    "    grad_mag = np.sqrt(h_grad**2 + v_grad**2)\n",
    "    \n",
    "    # Find local maxima (nuclei centers)\n",
    "    energy = ndimage.gaussian_filter(pred_np * (1 - grad_mag), sigma=1)\n",
    "    \n",
    "    # Watershed segmentation\n",
    "    markers = np.zeros_like(pred_np, dtype=np.int32)\n",
    "    \n",
    "    # Find peaks\n",
    "    coordinates = peak_local_max(\n",
    "        energy,\n",
    "        min_distance=5,\n",
    "        threshold_abs=0.1,\n",
    "        labels=pred_np_binary.astype(np.int32)\n",
    "    )\n",
    "    \n",
    "    if len(coordinates) == 0:\n",
    "        # Fallback: use connected components\n",
    "        instance_map, _ = scipy_label(pred_np_binary)\n",
    "        return instance_map\n",
    "    \n",
    "    for i, coord in enumerate(coordinates, start=1):\n",
    "        markers[coord[0], coord[1]] = i\n",
    "    \n",
    "    # Apply watershed\n",
    "    instance_map = watershed(-energy, markers, mask=pred_np_binary)\n",
    "    \n",
    "    return instance_map.astype(np.int32)\n",
    "\n",
    "\n",
    "def run_hovernet_inference_direct(model, image):\n",
    "    \"\"\"\n",
    "    Run HoverNet inference using direct model forward pass.\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded HoverNet model\n",
    "        image: RGB image (H, W, 3) uint8\n",
    "        \n",
    "    Returns:\n",
    "        dict: Segmentation results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess\n",
    "        img_tensor = preprocess_image(image)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "        \n",
    "        # Extract predictions\n",
    "        if isinstance(output, dict):\n",
    "            pred_np = output.get('np', output.get('NP', None))\n",
    "            pred_hv = output.get('hv', output.get('HV', None))\n",
    "        elif isinstance(output, (list, tuple)):\n",
    "            pred_np = output[0]\n",
    "            pred_hv = output[1] if len(output) > 1 else None\n",
    "        else:\n",
    "            pred_np = output\n",
    "            pred_hv = None\n",
    "        \n",
    "        # Convert to numpy\n",
    "        if pred_np is not None:\n",
    "            pred_np = torch.softmax(pred_np, dim=1)[0, 1].cpu().numpy()\n",
    "        \n",
    "        if pred_hv is not None:\n",
    "            pred_hv = pred_hv[0].permute(1, 2, 0).cpu().numpy()\n",
    "        else:\n",
    "            pred_hv = np.zeros((*pred_np.shape, 2))\n",
    "        \n",
    "        # Post-process\n",
    "        instance_map = post_process_nuclei(pred_np, pred_hv)\n",
    "        num_nuclei = len(np.unique(instance_map)) - 1  # Exclude background\n",
    "        \n",
    "        return {\n",
    "            'instance_map': instance_map,\n",
    "            'num_nuclei': max(0, num_nuclei),\n",
    "            'pred_np': pred_np\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Direct inference failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fallback_segmentation(image):\n",
    "    \"\"\"\n",
    "    Fallback nuclear segmentation using traditional CV methods.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image (H, W, 3)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Segmentation results\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Otsu thresholding\n",
    "    _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    # Distance transform for watershed\n",
    "    dist_transform = cv2.distanceTransform(binary, cv2.DIST_L2, 5)\n",
    "    \n",
    "    # Find local maxima\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.3 * dist_transform.max(), 255, 0)\n",
    "    sure_fg = sure_fg.astype(np.uint8)\n",
    "    \n",
    "    # Find unknown region\n",
    "    sure_bg = cv2.dilate(binary, kernel, iterations=3)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    \n",
    "    # Marker labelling\n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 1\n",
    "    markers[unknown == 255] = 0\n",
    "    \n",
    "    # Watershed\n",
    "    markers = cv2.watershed(image, markers)\n",
    "    \n",
    "    # Create instance map\n",
    "    instance_map = np.maximum(markers, 0).astype(np.int32)\n",
    "    instance_map[markers == -1] = 0  # Mark boundaries as background\n",
    "    \n",
    "    # Filter small regions\n",
    "    unique_ids = np.unique(instance_map)\n",
    "    for uid in unique_ids:\n",
    "        if uid <= 1:  # Skip background and borders\n",
    "            continue\n",
    "        mask = instance_map == uid\n",
    "        area = np.sum(mask)\n",
    "        if area < 50 or area > 5000:  # Filter by size\n",
    "            instance_map[mask] = 0\n",
    "    \n",
    "    # Relabel to ensure consecutive IDs\n",
    "    unique_ids = np.unique(instance_map)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    new_instance_map = np.zeros_like(instance_map)\n",
    "    for new_id, old_id in enumerate(unique_ids, start=1):\n",
    "        new_instance_map[instance_map == old_id] = new_id\n",
    "    \n",
    "    num_nuclei = len(unique_ids)\n",
    "    \n",
    "    return {\n",
    "        'instance_map': new_instance_map,\n",
    "        'num_nuclei': num_nuclei,\n",
    "        'pred_np': None\n",
    "    }\n",
    "\n",
    "\n",
    "def run_inference(image, use_model=True):\n",
    "    \"\"\"\n",
    "    Run nuclear segmentation inference.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image (H, W, 3) uint8\n",
    "        use_model: Whether to try using HoverNet model\n",
    "        \n",
    "    Returns:\n",
    "        dict: Segmentation results\n",
    "    \"\"\"\n",
    "    # Try HoverNet if available\n",
    "    if use_model and model is not None and HOVERNET_MODULES_AVAILABLE:\n",
    "        result = run_hovernet_inference_direct(model, image)\n",
    "        if result is not None:\n",
    "            return result\n",
    "    \n",
    "    # Fallback to traditional CV\n",
    "    return fallback_segmentation(image)\n",
    "\n",
    "\n",
    "print(\"✓ Inference functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Image Processing and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image and convert to RGB.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load: {image_path}\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def create_overlay(image, mask, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Create colorful overlay of segmentation on image.\n",
    "    \"\"\"\n",
    "    colored_mask = np.zeros_like(image)\n",
    "    \n",
    "    unique_ids = np.unique(mask)\n",
    "    unique_ids = unique_ids[unique_ids > 0]\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    colors = np.random.randint(50, 255, size=(len(unique_ids), 3))\n",
    "    \n",
    "    for idx, uid in enumerate(unique_ids):\n",
    "        colored_mask[mask == uid] = colors[idx]\n",
    "    \n",
    "    # Blend\n",
    "    overlay = cv2.addWeighted(image, 1 - alpha, colored_mask, alpha, 0)\n",
    "    \n",
    "    # Draw contours\n",
    "    for uid in unique_ids:\n",
    "        contours, _ = cv2.findContours(\n",
    "            (mask == uid).astype(np.uint8),\n",
    "            cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        cv2.drawContours(overlay, contours, -1, (255, 255, 0), 1)\n",
    "    \n",
    "    return overlay\n",
    "\n",
    "\n",
    "def save_results(output_dir, image_name, image, instance_map):\n",
    "    \"\"\"\n",
    "    Save segmentation results.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(image_name)[0]\n",
    "    \n",
    "    # Save original\n",
    "    orig_path = os.path.join(output_dir, f\"{base_name}_original.png\")\n",
    "    cv2.imwrite(orig_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    # Save mask\n",
    "    mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")\n",
    "    cv2.imwrite(mask_path, instance_map.astype(np.uint16))\n",
    "    \n",
    "    # Save overlay\n",
    "    overlay = create_overlay(image, instance_map)\n",
    "    overlay_path = os.path.join(output_dir, f\"{base_name}_overlay.png\")\n",
    "    cv2.imwrite(overlay_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    return {'original': orig_path, 'mask': mask_path, 'overlay': overlay_path}\n",
    "\n",
    "\n",
    "print(\"✓ Image processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = load_image(image_path)\n",
    "        result = run_inference(image)\n",
    "        \n",
    "        image_name = os.path.basename(image_path)\n",
    "        saved = save_results(output_dir, image_name, image, result['instance_map'])\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'image_name': image_name,\n",
    "            'num_nuclei': result['num_nuclei'],\n",
    "            'saved_paths': saved,\n",
    "            'error': None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'image_name': os.path.basename(image_path),\n",
    "            'num_nuclei': 0,\n",
    "            'saved_paths': None,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "def process_class(cell_class, max_images=None):\n",
    "    \"\"\"\n",
    "    Process all images for a cell class.\n",
    "    \"\"\"\n",
    "    input_dir = os.path.join(DATASET_BASE_PATH, cell_class, IMAGE_SUBFOLDER)\n",
    "    output_dir = os.path.join(OUTPUT_BASE_PATH, cell_class)\n",
    "    \n",
    "    images = sorted(glob.glob(os.path.join(input_dir, '*.bmp')))\n",
    "    if max_images:\n",
    "        images = images[:max_images]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {cell_class}\")\n",
    "    print(f\"Images: {len(images)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = []\n",
    "    for img_path in tqdm(images, desc=cell_class):\n",
    "        result = process_image(img_path, output_dir)\n",
    "        results.append(result)\n",
    "    \n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    total_nuclei = sum(r['num_nuclei'] for r in results if r['success'])\n",
    "    avg_nuclei = total_nuclei / successful if successful > 0 else 0\n",
    "    \n",
    "    print(f\"\\nSummary: {successful}/{len(images)} successful\")\n",
    "    print(f\"Total nuclei: {total_nuclei}, Avg: {avg_nuclei:.1f}\")\n",
    "    \n",
    "    return {\n",
    "        'cell_class': cell_class,\n",
    "        'total_images': len(images),\n",
    "        'successful': successful,\n",
    "        'failed': len(images) - successful,\n",
    "        'total_nuclei': total_nuclei,\n",
    "        'avg_nuclei_per_image': avg_nuclei\n",
    "    }\n",
    "\n",
    "\n",
    "def process_all(max_images_per_class=None):\n",
    "    \"\"\"\n",
    "    Process all cell classes.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING BATCH PROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    all_stats = {}\n",
    "    \n",
    "    for cell_class in CELL_CLASSES:\n",
    "        stats = process_class(cell_class, max_images_per_class)\n",
    "        all_stats[cell_class] = stats\n",
    "    \n",
    "    elapsed = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_images = sum(s['total_images'] for s in all_stats.values())\n",
    "    total_successful = sum(s['successful'] for s in all_stats.values())\n",
    "    total_nuclei = sum(s['total_nuclei'] for s in all_stats.values())\n",
    "    \n",
    "    overall = {\n",
    "        'processing_time_seconds': elapsed,\n",
    "        'total_images': total_images,\n",
    "        'total_successful': total_successful,\n",
    "        'total_failed': total_images - total_successful,\n",
    "        'total_nuclei_detected': total_nuclei,\n",
    "        'class_statistics': all_stats\n",
    "    }\n",
    "    \n",
    "    # Save statistics\n",
    "    stats_file = os.path.join(OUTPUT_BASE_PATH, 'processing_statistics.json')\n",
    "    with open(stats_file, 'w') as f:\n",
    "        json.dump(overall, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROCESSING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total: {total_images} images, {total_successful} successful\")\n",
    "    print(f\"Nuclei detected: {total_nuclei}\")\n",
    "    print(f\"Time: {elapsed:.1f}s ({elapsed/60:.1f} min)\")\n",
    "    print(f\"Stats saved: {stats_file}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return overall\n",
    "\n",
    "\n",
    "print(\"✓ Batch processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(cell_class, n=3):\n",
    "    \"\"\"\n",
    "    Visualize sample results.\n",
    "    \"\"\"\n",
    "    output_dir = os.path.join(OUTPUT_BASE_PATH, cell_class)\n",
    "    overlays = sorted(glob.glob(os.path.join(output_dir, '*_overlay.png')))\n",
    "    \n",
    "    if not overlays:\n",
    "        print(f\"No results for {cell_class}\")\n",
    "        return\n",
    "    \n",
    "    import random\n",
    "    samples = random.sample(overlays, min(n, len(overlays)))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(samples), figsize=(5*len(samples), 5))\n",
    "    if len(samples) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, path in enumerate(samples):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(cell_class.replace('im_', ''))\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_stats(stats):\n",
    "    \"\"\"\n",
    "    Plot statistics.\n",
    "    \"\"\"\n",
    "    class_stats = stats['class_statistics']\n",
    "    classes = list(class_stats.keys())\n",
    "    labels = [c.replace('im_', '') for c in classes]\n",
    "    \n",
    "    nuclei = [class_stats[c]['total_nuclei'] for c in classes]\n",
    "    avg = [class_stats[c]['avg_nuclei_per_image'] for c in classes]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    ax1.bar(range(len(classes)), nuclei, color='steelblue')\n",
    "    ax1.set_xticks(range(len(classes)))\n",
    "    ax1.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Total Nuclei')\n",
    "    ax1.set_title('Total Nuclei per Class')\n",
    "    \n",
    "    ax2.bar(range(len(classes)), avg, color='coral')\n",
    "    ax2.set_xticks(range(len(classes)))\n",
    "    ax2.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Avg Nuclei per Image')\n",
    "    ax2.set_title('Average Nuclei per Image')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"✓ Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Run Processing\n",
    "\n",
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on first class with 5 images\n",
    "if WEIGHT_FILE and dataset_valid:\n",
    "    print(\"Running test with 5 images...\\n\")\n",
    "    test_stats = process_class(CELL_CLASSES[0], max_images=5)\n",
    "    \n",
    "    if test_stats['successful'] > 0:\n",
    "        print(\"\\n✓ Test successful!\")\n",
    "        visualize_samples(CELL_CLASSES[0], n=3)\n",
    "    else:\n",
    "        print(\"\\n❌ Test failed\")\n",
    "else:\n",
    "    print(\"❌ Cannot run - check configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process All Classes (Limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process 50 images per class\n",
    "if WEIGHT_FILE and dataset_valid:\n",
    "    overall_stats = process_all(max_images_per_class=50)\n",
    "else:\n",
    "    print(\"❌ Cannot run - check configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process All Images (Full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to process ALL images\n",
    "# if WEIGHT_FILE and dataset_valid:\n",
    "#     overall_stats = process_all()\n",
    "# else:\n",
    "#     print(\"❌ Cannot run - check configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples from each class\n",
    "if 'overall_stats' in locals():\n",
    "    for cell_class in CELL_CLASSES:\n",
    "        print(f\"\\n{cell_class}:\")\n",
    "        visualize_samples(cell_class, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot statistics\n",
    "if 'overall_stats' in locals():\n",
    "    plot_stats(overall_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean temp files\n",
    "if os.path.exists(TEMP_DIR):\n",
    "    shutil.rmtree(TEMP_DIR)\n",
    "    print(f\"✓ Cleaned: {TEMP_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Output Structure\n",
    "```\n",
    "HoverNet_Segmentation_Results/\n",
    "├── im_Dyskeratotic/\n",
    "│   ├── image_original.png\n",
    "│   ├── image_mask.png\n",
    "│   └── image_overlay.png\n",
    "├── im_Koilocytotic/\n",
    "├── im_Metaplastic/\n",
    "├── im_Parabasal/\n",
    "├── im_Superficial-Intermediate/\n",
    "└── processing_statistics.json\n",
    "```\n",
    "\n",
    "### Troubleshooting\n",
    "- **Model loading fails**: Ensure the .tar file is a valid HoverNet checkpoint\n",
    "- **Out of memory**: Reduce batch size or use fewer images\n",
    "- **Poor results**: The fallback CV method is used if HoverNet fails\n",
    "\n",
    "### References\n",
    "- [HoverNet Paper](https://arxiv.org/abs/1812.06499)\n",
    "- [HoverNet GitHub](https://github.com/vqdang/hover_net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

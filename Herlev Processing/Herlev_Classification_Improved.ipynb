{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Cervical Cancer Cell Classification\n",
    "## Project Phoenix - Enhanced Pipeline\n",
    "\n",
    "**Improvements over baseline:**\n",
    "1. Proper train/validation/test split\n",
    "2. Class-weighted loss for imbalanced data\n",
    "3. Modern architectures (EfficientNet, ConvNeXt)\n",
    "4. Cosine annealing with warm restarts\n",
    "5. Mixup and CutMix augmentation\n",
    "6. Gradual unfreezing for fine-tuning\n",
    "7. Ensemble methods\n",
    "8. Test-time augmentation (TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install torch torchvision timm scikit-learn matplotlib seaborn pillow tqdm shap streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# timm for modern architectures\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    precision_recall_fscore_support, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = \"/content/drive/MyDrive/Projects/6_Project Phoenix_Cervical Cancer Cell Classification/Herlev Dataset/Preprocessing Analysis v3.0\"\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, \"train\")\n",
    "TEST_PATH = os.path.join(DATA_PATH, \"test\")\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16  # Smaller batch for better generalization\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4  # Lower LR for fine-tuning\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_CLASSES = 7\n",
    "VAL_SPLIT = 0.15  # 15% of training data for validation\n",
    "\n",
    "# Early stopping\n",
    "PATIENCE = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading with Proper Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HerlevDataset(Dataset):\n",
    "    \"\"\"Enhanced dataset with support for various augmentations.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "def load_data_paths(root_dir):\n",
    "    \"\"\"Load all image paths and labels from directory.\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(root_dir))\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(root_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_name in os.listdir(class_path):\n",
    "                if img_name.lower().endswith(('.bmp', '.png', '.jpg', '.jpeg')):\n",
    "                    image_paths.append(os.path.join(class_path, img_name))\n",
    "                    labels.append(class_to_idx[class_name])\n",
    "    \n",
    "    return image_paths, labels, class_to_idx\n",
    "\n",
    "\n",
    "# Load paths\n",
    "train_paths, train_labels, class_to_idx = load_data_paths(TRAIN_PATH)\n",
    "test_paths, test_labels, _ = load_data_paths(TEST_PATH)\n",
    "\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "print(f\"Total training samples: {len(train_paths)}\")\n",
    "print(f\"Total test samples: {len(test_paths)}\")\n",
    "print(f\"Classes: {list(class_to_idx.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training into train and validation (stratified)\n",
    "train_paths_split, val_paths, train_labels_split, val_labels = train_test_split(\n",
    "    train_paths, train_labels, \n",
    "    test_size=VAL_SPLIT, \n",
    "    stratify=train_labels,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_paths_split)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")\n",
    "print(f\"Test samples: {len(test_paths)}\")\n",
    "\n",
    "# Class distribution\n",
    "print(\"\\nTraining class distribution:\")\n",
    "for cls_idx, count in sorted(Counter(train_labels_split).items()):\n",
    "    print(f\"  {idx_to_class[cls_idx]}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "class_counts = Counter(train_labels_split)\n",
    "total_samples = len(train_labels_split)\n",
    "class_weights = torch.tensor([\n",
    "    total_samples / (NUM_CLASSES * class_counts[i]) \n",
    "    for i in range(NUM_CLASSES)\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for i, w in enumerate(class_weights):\n",
    "    print(f\"  {idx_to_class[i]}: {w:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong augmentation for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),  # Resize larger for random crop\n",
    "    transforms.RandomCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.2))  # Cutout-like augmentation\n",
    "])\n",
    "\n",
    "# Validation/Test transform (no augmentation)\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# TTA transforms\n",
    "tta_transforms = [\n",
    "    eval_transform,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomVerticalFlip(p=1.0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomRotation((90, 90)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = HerlevDataset(train_paths_split, train_labels_split, transform=train_transform)\n",
    "val_dataset = HerlevDataset(val_paths, val_labels, transform=eval_transform)\n",
    "test_dataset = HerlevDataset(test_paths, test_labels, transform=eval_transform)\n",
    "\n",
    "# Weighted sampler for balanced batches\n",
    "sample_weights = [1.0 / class_counts[label] for label in train_labels_split]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mixup Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.4):\n",
    "    \"\"\"Apply mixup augmentation.\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Compute mixup loss.\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, num_classes, pretrained=True):\n",
    "    \"\"\"Create model using timm library for modern architectures.\"\"\"\n",
    "    \n",
    "    if model_name == 'efficientnet_b0':\n",
    "        model = timm.create_model('efficientnet_b0', pretrained=pretrained, num_classes=num_classes)\n",
    "    elif model_name == 'efficientnet_b2':\n",
    "        model = timm.create_model('efficientnet_b2', pretrained=pretrained, num_classes=num_classes)\n",
    "    elif model_name == 'convnext_tiny':\n",
    "        model = timm.create_model('convnext_tiny', pretrained=pretrained, num_classes=num_classes)\n",
    "    elif model_name == 'convnext_small':\n",
    "        model = timm.create_model('convnext_small', pretrained=pretrained, num_classes=num_classes)\n",
    "    elif model_name == 'resnet50':\n",
    "        model = timm.create_model('resnet50', pretrained=pretrained, num_classes=num_classes)\n",
    "    elif model_name == 'densenet121':\n",
    "        model = timm.create_model('densenet121', pretrained=pretrained, num_classes=num_classes)\n",
    "    elif model_name == 'swin_tiny':\n",
    "        model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=pretrained, num_classes=num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "# List available models\n",
    "print(\"Models to evaluate:\")\n",
    "model_names = ['efficientnet_b0', 'efficientnet_b2', 'convnext_tiny', 'swin_tiny']\n",
    "for m in model_names:\n",
    "    print(f\"  - {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training with Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting.\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=7, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "    \n",
    "    def __call__(self, val_score, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "            self.best_model = model.state_dict().copy()\n",
    "        elif val_score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.best_model = model.state_dict().copy()\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, use_mixup=True):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_mixup and np.random.random() > 0.5:\n",
    "            images, labels_a, labels_b, lam = mixup_data(images, labels)\n",
    "            outputs = model(images)\n",
    "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    \"\"\"Evaluate model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return total_loss / len(all_labels), acc, bal_acc, np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs, model_name):\n",
    "    \"\"\"Full training loop with cosine annealing and early stopping.\"\"\"\n",
    "    \n",
    "    # Loss with class weights\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "    \n",
    "    # Optimizer with weight decay\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # Cosine annealing scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=PATIENCE)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_bal_acc': []}\n",
    "    \n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, use_mixup=True)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, val_bal_acc, _, _ = evaluate(model, val_loader, criterion)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_bal_acc'].append(val_bal_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:02d}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
    "              f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}, Val Bal Acc={val_bal_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopping(val_bal_acc, model):\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(early_stopping.best_model)\n",
    "    \n",
    "    return model, history, early_stopping.best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and compare models\n",
    "models_to_train = ['efficientnet_b0', 'efficientnet_b2', 'convnext_tiny', 'swin_tiny']\n",
    "results = {}\n",
    "\n",
    "for model_name in models_to_train:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Model: {model_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model = create_model(model_name, NUM_CLASSES)\n",
    "    model, history, best_val_score = train_model(model, train_loader, val_loader, NUM_EPOCHS, model_name)\n",
    "    \n",
    "    # Test evaluation\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    test_loss, test_acc, test_bal_acc, preds, labels = evaluate(model, test_loader, criterion)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'best_val_score': best_val_score,\n",
    "        'test_acc': test_acc,\n",
    "        'test_bal_acc': test_bal_acc,\n",
    "        'predictions': preds,\n",
    "        'labels': labels\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test Balanced Accuracy: {test_bal_acc:.4f}\")\n",
    "    print(classification_report(labels, preds, target_names=list(class_to_idx.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test-Time Augmentation (TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_tta(model, image_paths, labels, tta_transforms):\n",
    "    \"\"\"Make predictions using test-time augmentation.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img_path in tqdm(image_paths, desc=\"TTA Prediction\"):\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Aggregate predictions from all TTA transforms\n",
    "            probs_list = []\n",
    "            for transform in tta_transforms:\n",
    "                img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "                output = model(img_tensor)\n",
    "                probs = F.softmax(output, dim=1)\n",
    "                probs_list.append(probs.cpu().numpy())\n",
    "            \n",
    "            # Average probabilities\n",
    "            avg_probs = np.mean(probs_list, axis=0)\n",
    "            pred = np.argmax(avg_probs)\n",
    "            \n",
    "            all_preds.append(pred)\n",
    "            all_probs.append(avg_probs[0])\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_probs)\n",
    "\n",
    "# Apply TTA to best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['test_bal_acc'])\n",
    "print(f\"\\nApplying TTA to best model: {best_model_name}\")\n",
    "\n",
    "best_model = results[best_model_name]['model']\n",
    "tta_preds, tta_probs = predict_with_tta(best_model, test_paths, test_labels, tta_transforms)\n",
    "\n",
    "tta_acc = accuracy_score(test_labels, tta_preds)\n",
    "tta_bal_acc = balanced_accuracy_score(test_labels, tta_preds)\n",
    "\n",
    "print(f\"\\nTTA Results for {best_model_name}:\")\n",
    "print(f\"  Accuracy: {tta_acc:.4f}\")\n",
    "print(f\"  Balanced Accuracy: {tta_bal_acc:.4f}\")\n",
    "print(classification_report(test_labels, tta_preds, target_names=list(class_to_idx.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_probabilities(model, dataloader):\n",
    "    \"\"\"Get probability predictions from a model.\"\"\"\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.vstack(all_probs), np.array(all_labels)\n",
    "\n",
    "\n",
    "# Ensemble predictions from all models\n",
    "print(\"\\nCreating ensemble from all trained models...\")\n",
    "\n",
    "ensemble_probs = []\n",
    "for model_name, result in results.items():\n",
    "    probs, labels = get_model_probabilities(result['model'], test_loader)\n",
    "    ensemble_probs.append(probs)\n",
    "    print(f\"  Added {model_name}\")\n",
    "\n",
    "# Average ensemble\n",
    "avg_ensemble_probs = np.mean(ensemble_probs, axis=0)\n",
    "ensemble_preds = np.argmax(avg_ensemble_probs, axis=1)\n",
    "\n",
    "ensemble_acc = accuracy_score(labels, ensemble_preds)\n",
    "ensemble_bal_acc = balanced_accuracy_score(labels, ensemble_preds)\n",
    "\n",
    "print(f\"\\nEnsemble Results:\")\n",
    "print(f\"  Accuracy: {ensemble_acc:.4f}\")\n",
    "print(f\"  Balanced Accuracy: {ensemble_bal_acc:.4f}\")\n",
    "print(classification_report(labels, ensemble_preds, target_names=list(class_to_idx.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Enhanced Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_multi_model(models_dict, dataloader):\n",
    "    \"\"\"Extract and concatenate features from multiple models.\"\"\"\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "        images = images.to(device)\n",
    "        batch_features = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for model_name, result in models_dict.items():\n",
    "                model = result['model']\n",
    "                model.eval()\n",
    "                \n",
    "                # Get features before final classifier\n",
    "                if 'efficientnet' in model_name:\n",
    "                    features = model.forward_features(images)\n",
    "                    features = model.global_pool(features)\n",
    "                elif 'convnext' in model_name:\n",
    "                    features = model.forward_features(images)\n",
    "                    features = model.head.global_pool(features)\n",
    "                elif 'swin' in model_name:\n",
    "                    features = model.forward_features(images)\n",
    "                else:\n",
    "                    features = model.forward_features(images)\n",
    "                    if len(features.shape) > 2:\n",
    "                        features = F.adaptive_avg_pool2d(features, 1).flatten(1)\n",
    "                \n",
    "                if len(features.shape) > 2:\n",
    "                    features = features.mean(dim=(1, 2)) if len(features.shape) == 4 else features.mean(dim=1)\n",
    "                \n",
    "                batch_features.append(features.cpu().numpy())\n",
    "        \n",
    "        # Concatenate features from all models\n",
    "        combined = np.concatenate(batch_features, axis=1)\n",
    "        all_features.append(combined)\n",
    "        all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.vstack(all_features), np.array(all_labels)\n",
    "\n",
    "\n",
    "# Extract multi-model features\n",
    "print(\"Extracting features from all models...\")\n",
    "X_train_feat, y_train_feat = extract_features_multi_model(results, train_loader)\n",
    "X_val_feat, y_val_feat = extract_features_multi_model(results, val_loader)\n",
    "X_test_feat, y_test_feat = extract_features_multi_model(results, test_loader)\n",
    "\n",
    "print(f\"Combined feature dimensions: {X_train_feat.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_feat)\n",
    "X_val_scaled = scaler.transform(X_val_feat)\n",
    "X_test_scaled = scaler.transform(X_test_feat)\n",
    "\n",
    "# Try multiple classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=2000, C=0.1, random_state=SEED),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=SEED),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=20, random_state=SEED),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=SEED)\n",
    "}\n",
    "\n",
    "hybrid_results = {}\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {clf_name}...\")\n",
    "    clf.fit(X_train_scaled, y_train_feat)\n",
    "    \n",
    "    # Validation\n",
    "    val_preds = clf.predict(X_val_scaled)\n",
    "    val_acc = accuracy_score(y_val_feat, val_preds)\n",
    "    val_bal_acc = balanced_accuracy_score(y_val_feat, val_preds)\n",
    "    \n",
    "    # Test\n",
    "    test_preds = clf.predict(X_test_scaled)\n",
    "    test_acc = accuracy_score(y_test_feat, test_preds)\n",
    "    test_bal_acc = balanced_accuracy_score(y_test_feat, test_preds)\n",
    "    \n",
    "    hybrid_results[clf_name] = {\n",
    "        'classifier': clf,\n",
    "        'val_acc': val_acc,\n",
    "        'val_bal_acc': val_bal_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'test_bal_acc': test_bal_acc,\n",
    "        'predictions': test_preds\n",
    "    }\n",
    "    \n",
    "    print(f\"  Val Acc: {val_acc:.4f}, Val Bal Acc: {val_bal_acc:.4f}\")\n",
    "    print(f\"  Test Acc: {test_acc:.4f}, Test Bal Acc: {test_bal_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "final_results = []\n",
    "\n",
    "# Individual models\n",
    "for model_name, result in results.items():\n",
    "    final_results.append({\n",
    "        'Method': f\"{model_name} (Fine-tuned)\",\n",
    "        'Test Accuracy': result['test_acc'],\n",
    "        'Balanced Accuracy': result['test_bal_acc']\n",
    "    })\n",
    "\n",
    "# TTA\n",
    "final_results.append({\n",
    "    'Method': f\"{best_model_name} + TTA\",\n",
    "    'Test Accuracy': tta_acc,\n",
    "    'Balanced Accuracy': tta_bal_acc\n",
    "})\n",
    "\n",
    "# Ensemble\n",
    "final_results.append({\n",
    "    'Method': 'Model Ensemble (Avg)',\n",
    "    'Test Accuracy': ensemble_acc,\n",
    "    'Balanced Accuracy': ensemble_bal_acc\n",
    "})\n",
    "\n",
    "# Hybrid models\n",
    "for clf_name, result in hybrid_results.items():\n",
    "    final_results.append({\n",
    "        'Method': f\"Hybrid + {clf_name}\",\n",
    "        'Test Accuracy': result['test_acc'],\n",
    "        'Balanced Accuracy': result['test_bal_acc']\n",
    "    })\n",
    "\n",
    "# Create dataframe and sort\n",
    "final_df = pd.DataFrame(final_results)\n",
    "final_df = final_df.sort_values('Balanced Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(final_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(final_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.barh(x - width/2, final_df['Test Accuracy'], width, label='Accuracy', color='#3498db')\n",
    "bars2 = ax.barh(x + width/2, final_df['Balanced Accuracy'], width, label='Balanced Accuracy', color='#2ecc71')\n",
    "\n",
    "ax.set_xlabel('Score')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(final_df['Method'])\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 1)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model confusion matrix\n",
    "best_method = final_df.iloc[0]['Method']\n",
    "print(f\"\\nBest Method: {best_method}\")\n",
    "\n",
    "# Get predictions for best method\n",
    "if 'Hybrid' in best_method:\n",
    "    clf_name = best_method.replace('Hybrid + ', '')\n",
    "    best_preds = hybrid_results[clf_name]['predictions']\n",
    "    best_labels = y_test_feat\n",
    "elif 'TTA' in best_method:\n",
    "    best_preds = tta_preds\n",
    "    best_labels = test_labels\n",
    "elif 'Ensemble' in best_method:\n",
    "    best_preds = ensemble_preds\n",
    "    best_labels = labels\n",
    "else:\n",
    "    model_name = best_method.replace(' (Fine-tuned)', '')\n",
    "    best_preds = results[model_name]['predictions']\n",
    "    best_labels = results[model_name]['labels']\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(best_labels, best_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=list(class_to_idx.keys()),\n",
    "            yticklabels=list(class_to_idx.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix - {best_method}')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(best_labels, best_preds, target_names=list(class_to_idx.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. SHAP Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Use the best hybrid classifier for SHAP\n",
    "best_clf_name = max(hybrid_results, key=lambda x: hybrid_results[x]['test_bal_acc'])\n",
    "best_clf = hybrid_results[best_clf_name]['classifier']\n",
    "\n",
    "print(f\"Using {best_clf_name} for SHAP analysis...\")\n",
    "\n",
    "# Sample background data\n",
    "background_size = min(100, len(X_train_scaled))\n",
    "background_idx = np.random.choice(len(X_train_scaled), background_size, replace=False)\n",
    "background = X_train_scaled[background_idx]\n",
    "\n",
    "# Create explainer\n",
    "if hasattr(best_clf, 'predict_proba'):\n",
    "    explainer = shap.KernelExplainer(best_clf.predict_proba, background)\n",
    "else:\n",
    "    explainer = shap.KernelExplainer(best_clf.predict, background)\n",
    "\n",
    "# Calculate SHAP values for test subset\n",
    "test_subset_size = min(30, len(X_test_scaled))\n",
    "test_idx = np.random.choice(len(X_test_scaled), test_subset_size, replace=False)\n",
    "X_test_subset = X_test_scaled[test_idx]\n",
    "\n",
    "print(f\"Calculating SHAP values for {test_subset_size} samples...\")\n",
    "shap_values = explainer.shap_values(X_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance summary\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    # Multi-class: average importance across classes\n",
    "    mean_abs_shap = np.mean([np.abs(sv).mean(axis=0) for sv in shap_values], axis=0)\n",
    "else:\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Top 30 features\n",
    "top_k = 30\n",
    "top_idx = np.argsort(mean_abs_shap)[-top_k:]\n",
    "\n",
    "plt.barh(range(top_k), mean_abs_shap[top_idx], color='steelblue')\n",
    "plt.yticks(range(top_k), [f\"Feature {i}\" for i in top_idx])\n",
    "plt.xlabel('Mean |SHAP value|')\n",
    "plt.title('Top 30 Most Important Combined Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "SAVE_DIR = \"./saved_models_improved\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Save all trained models\n",
    "for model_name, result in results.items():\n",
    "    torch.save(result['model'].state_dict(), os.path.join(SAVE_DIR, f\"{model_name}.pth\"))\n",
    "\n",
    "# Save best hybrid classifier\n",
    "with open(os.path.join(SAVE_DIR, \"best_hybrid_classifier.pkl\"), 'wb') as f:\n",
    "    pickle.dump(best_clf, f)\n",
    "\n",
    "with open(os.path.join(SAVE_DIR, \"feature_scaler.pkl\"), 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open(os.path.join(SAVE_DIR, \"class_mapping.pkl\"), 'wb') as f:\n",
    "    pickle.dump(class_to_idx, f)\n",
    "\n",
    "# Save results\n",
    "final_df.to_csv(os.path.join(SAVE_DIR, \"model_comparison.csv\"), index=False)\n",
    "\n",
    "print(f\"Models saved to {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Updated Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_code = '''\n",
    "\"\"\"\n",
    "Project Phoenix - Improved Classification Dashboard\n",
    "Run: streamlit run streamlit_app_improved.py\n",
    "\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import timm\n",
    "import os\n",
    "\n",
    "st.set_page_config(page_title=\"Project Phoenix\", page_icon=\"üî¨\", layout=\"wide\")\n",
    "\n",
    "MODELS_DIR = \"./saved_models_improved\"\n",
    "IMG_SIZE = 224\n",
    "\n",
    "@st.cache_resource\n",
    "def load_models():\n",
    "    device = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\n",
    "    \n",
    "    # Load all CNN models\n",
    "    model_configs = [\n",
    "        (\\'efficientnet_b0\\', \\'efficientnet_b0\\'),\n",
    "        (\\'efficientnet_b2\\', \\'efficientnet_b2\\'),\n",
    "        (\\'convnext_tiny\\', \\'convnext_tiny\\'),\n",
    "        (\\'swin_tiny\\', \\'swin_tiny_patch4_window7_224\\')\n",
    "    ]\n",
    "    \n",
    "    models = {}\n",
    "    for name, timm_name in model_configs:\n",
    "        model = timm.create_model(timm_name, pretrained=False, num_classes=7)\n",
    "        model.load_state_dict(torch.load(os.path.join(MODELS_DIR, f\"{name}.pth\"), map_location=device))\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        models[name] = model\n",
    "    \n",
    "    with open(os.path.join(MODELS_DIR, \"class_mapping.pkl\"), \\'rb\\') as f:\n",
    "        class_mapping = pickle.load(f)\n",
    "    \n",
    "    return models, class_mapping, device\n",
    "\n",
    "def preprocess(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "def ensemble_predict(models, image, device):\n",
    "    img_tensor = preprocess(image).to(device)\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for model in models.values():\n",
    "            output = model(img_tensor)\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    avg_probs = np.mean(all_probs, axis=0)[0]\n",
    "    pred_class = np.argmax(avg_probs)\n",
    "    return pred_class, avg_probs\n",
    "\n",
    "def main():\n",
    "    st.title(\"üî¨ Project Phoenix\")\n",
    "    st.subheader(\"Cervical Cancer Cell Classification (Improved)\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    st.sidebar.title(\"About\")\n",
    "    st.sidebar.info(\n",
    "        \"Enhanced model using ensemble of EfficientNet, ConvNeXt, and Swin Transformer.\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        models, class_mapping, device = load_models()\n",
    "        st.success(f\"Loaded {len(models)} models for ensemble prediction\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading models: {e}\")\n",
    "        return\n",
    "    \n",
    "    idx_to_class = {v: k for k, v in class_mapping.items()}\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Upload Image\")\n",
    "        uploaded = st.file_uploader(\"Choose cell image...\", type=[\\'bmp\\', \\'png\\', \\'jpg\\', \\'jpeg\\'])\n",
    "        \n",
    "        if uploaded:\n",
    "            image = Image.open(uploaded).convert(\\'RGB\\')\n",
    "            st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(\"Results\")\n",
    "        \n",
    "        if uploaded and st.button(\"Classify\", type=\"primary\"):\n",
    "            with st.spinner(\"Analyzing with ensemble...\"):\n",
    "                pred_idx, probs = ensemble_predict(models, image, device)\n",
    "                pred_class = idx_to_class[pred_idx]\n",
    "            \n",
    "            st.success(f\"**Predicted:** {pred_class.replace(\\'_\\', \\' \\').title()}\")\n",
    "            st.write(f\"**Confidence:** {probs[pred_idx]*100:.1f}%\")\n",
    "            \n",
    "            st.subheader(\"Class Probabilities\")\n",
    "            prob_dict = {idx_to_class[i].replace(\\'_\\', \\' \\').title(): float(probs[i]) for i in range(len(probs))}\n",
    "            st.bar_chart(prob_dict)\n",
    "            \n",
    "            abnormal = [\\'carcinoma_in_situ\\', \\'light_dysplastic\\', \\'moderate_dysplastic\\', \\'severe_dysplastic\\']\n",
    "            if pred_class in abnormal:\n",
    "                st.warning(\"‚ö†Ô∏è Abnormal cell detected. Consult a medical professional.\")\n",
    "            else:\n",
    "                st.info(\"‚úÖ Cell appears normal.\")\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    st.caption(\"Disclaimer: For research purposes only.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open(\"streamlit_app_improved.py\", 'w') as f:\n",
    "    f.write(streamlit_code)\n",
    "\n",
    "print(\"Streamlit app saved as 'streamlit_app_improved.py'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Improvements:**\n",
    "\n",
    "1. **Proper validation split** - 15% of training data for validation\n",
    "2. **Class-weighted loss** - Handles imbalanced classes\n",
    "3. **Modern architectures** - EfficientNet, ConvNeXt, Swin Transformer\n",
    "4. **Strong augmentation** - RandomErasing, ColorJitter, GaussianBlur\n",
    "5. **Mixup augmentation** - Regularization during training\n",
    "6. **Weighted sampling** - Balanced batches\n",
    "7. **Label smoothing** - Prevents overconfidence\n",
    "8. **AdamW + Cosine annealing** - Better optimization\n",
    "9. **Early stopping** - Prevents overfitting\n",
    "10. **Test-time augmentation** - Improved test accuracy\n",
    "11. **Model ensemble** - Combines multiple models\n",
    "12. **Multi-model hybrid** - Features from all models + ML classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPROVED PIPELINE COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d10d1c",
   "metadata": {},
   "source": [
    "# Nucleus Mask Explainability v0.1\n",
    "\n",
    "This notebook implements robust nucleus segmentation using Cellpose for cervical cancer cell images. It processes images from the augmented dataset and generates high-quality nucleus masks for explainability analysis.\n",
    "\n",
    "## Project Overview\n",
    "- **Dataset**: Cervical cancer cell images from 5 categories (Dyskeratotic, Koilocytotic, Metaplastic, Parabasal, Superficial-Intermediate)\n",
    "- **Goal**: Generate nucleus masks using Cellpose for downstream explainability analysis\n",
    "- **Output**: Segmentation masks stored in \"Nucleus Masks\" folders with evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f845535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Basic libraries imported successfully\n",
      "ðŸ“Š NumPy version: 1.26.4\n",
      "ðŸ–¼ï¸ OpenCV version: 4.12.0\n",
      "ðŸ“ˆ Matplotlib version: 3.8.3\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"âœ… Basic libraries imported successfully\")\n",
    "print(f\"ðŸ“Š NumPy version: {np.__version__}\")\n",
    "print(f\"ðŸ–¼ï¸ OpenCV version: {cv2.__version__}\")\n",
    "print(f\"ðŸ“ˆ Matplotlib version: {plt.matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5610e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \twin32 \n",
      "python version: \t3.12.10 \n",
      "torch version:  \t2.2.2+cpu! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n",
      "âœ… Cellpose imported successfully\n",
      "âœ… Cellpose imported successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 15:55:17,540 - INFO - Neither TORCH CUDA nor MPS version not installed/working.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ GPU available for Cellpose: False\n",
      "   Using CPU for segmentation\n",
      "âœ… All specialized libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import Cellpose and specialized libraries for segmentation\n",
    "try:\n",
    "    from cellpose import models, core, utils, plot\n",
    "    from cellpose.io import imread\n",
    "    print(\"âœ… Cellpose imported successfully\")\n",
    "    \n",
    "    # Check if GPU is available for Cellpose\n",
    "    use_GPU = core.use_gpu()\n",
    "    print(f\"ðŸ”¥ GPU available for Cellpose: {use_GPU}\")\n",
    "    if use_GPU:\n",
    "        print(\"   Using GPU acceleration for segmentation\")\n",
    "    else:\n",
    "        print(\"   Using CPU for segmentation\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(\"âŒ Error importing Cellpose:\", str(e))\n",
    "    print(\"Please install Cellpose using: pip install cellpose\")\n",
    "\n",
    "# Additional specialized imports\n",
    "from skimage import measure, morphology, segmentation, filters\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy import ndimage\n",
    "from natsort import natsorted\n",
    "import time\n",
    "\n",
    "print(\"âœ… All specialized libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f5d3cf",
   "metadata": {},
   "source": [
    "## Configuration and Data Structures\n",
    "\n",
    "Let's define the configuration parameters and data structures that will be used throughout the segmentation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22e292f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration initialized\n",
      "ðŸ“‚ Dataset root: c:\\Meet\\Projects\\Project_8_Phoenix_Cervical Cancer Image Classification\\Project-Phoenix\\Dataset\\Augmented Dataset - Limited Enhancement\n",
      "ðŸ·ï¸ Cell categories: 5\n",
      "ðŸ”¬ Model type: nuclei\n",
      "ðŸ“ Diameter estimation: Auto\n",
      "ðŸŒŠ Flow threshold: 0.4\n",
      "ðŸ“Š Cell probability threshold: 0.0\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class SegmentationConfig:\n",
    "    \"\"\"Configuration class for nucleus segmentation parameters.\"\"\"\n",
    "    \n",
    "    # Dataset paths\n",
    "    dataset_root: str = r\"c:\\Meet\\Projects\\Project_8_Phoenix_Cervical Cancer Image Classification\\Project-Phoenix\\Dataset\\Augmented Dataset - Limited Enhancement\"\n",
    "    input_folder: str = \"NLM_CLAHE\"\n",
    "    output_folder: str = \"Nucleus Masks\"\n",
    "    \n",
    "    # Cell categories\n",
    "    cell_categories: List[str] = None\n",
    "    \n",
    "    # Cellpose parameters\n",
    "    model_type: str = \"nuclei\"  # Options: 'cyto', 'nuclei', 'cyto2', 'CP'\n",
    "    diameter: Optional[int] = None  # Let Cellpose estimate\n",
    "    channels: List[int] = None  # [0, 0] for grayscale\n",
    "    flow_threshold: float = 0.4  # Default flow threshold\n",
    "    cellprob_threshold: float = 0.0  # Default cell probability threshold\n",
    "    \n",
    "    # Image processing parameters\n",
    "    min_nucleus_size: int = 50  # Minimum nucleus area in pixels\n",
    "    max_nucleus_size: int = 5000  # Maximum nucleus area in pixels\n",
    "    \n",
    "    # Visualization parameters\n",
    "    figsize: Tuple[int, int] = (15, 10)\n",
    "    dpi: int = 100\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Initialize derived attributes after dataclass creation.\"\"\"\n",
    "        if self.cell_categories is None:\n",
    "            self.cell_categories = [\n",
    "                \"im_Dyskeratotic\",\n",
    "                \"im_Koilocytotic\", \n",
    "                \"im_Metaplastic\",\n",
    "                \"im_Parabasal\",\n",
    "                \"im_Superficial-Intermediate\"\n",
    "            ]\n",
    "        \n",
    "        if self.channels is None:\n",
    "            self.channels = [0, 0]  # Grayscale processing\n",
    "\n",
    "# Create configuration instance\n",
    "config = SegmentationConfig()\n",
    "\n",
    "print(\"âœ… Configuration initialized\")\n",
    "print(f\"ðŸ“‚ Dataset root: {config.dataset_root}\")\n",
    "print(f\"ðŸ·ï¸ Cell categories: {len(config.cell_categories)}\")\n",
    "print(f\"ðŸ”¬ Model type: {config.model_type}\")\n",
    "print(f\"ðŸ“ Diameter estimation: {'Auto' if config.diameter is None else config.diameter}\")\n",
    "print(f\"ðŸŒŠ Flow threshold: {config.flow_threshold}\")\n",
    "print(f\"ðŸ“Š Cell probability threshold: {config.cellprob_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9275fd",
   "metadata": {},
   "source": [
    "## Nucleus Segmentation Functions\n",
    "\n",
    "Let's implement robust functions for nucleus segmentation using Cellpose with comprehensive error handling and quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3605d1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 15:55:17,616 - INFO - Neither TORCH CUDA nor MPS version not installed/working.\n",
      "2025-09-25 15:55:17,617 - WARNING - model_type argument is not used in v4.0.1+. Ignoring this argument...\n",
      "2025-09-25 15:55:17,619 - INFO - >>>> using CPU\n",
      "2025-09-25 15:55:17,621 - INFO - >>>> using CPU\n",
      "2025-09-25 15:55:17,617 - WARNING - model_type argument is not used in v4.0.1+. Ignoring this argument...\n",
      "2025-09-25 15:55:17,619 - INFO - >>>> using CPU\n",
      "2025-09-25 15:55:17,621 - INFO - >>>> using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 15:55:20,762 - INFO - >>>> loading model C:\\Users\\meetb\\.cellpose\\models\\cpsam\n",
      "2025-09-25 15:55:23,629 - INFO - Cellpose model 'nuclei' initialized successfully\n",
      "2025-09-25 15:55:23,634 - INFO - Neither TORCH CUDA nor MPS version not installed/working.\n",
      "2025-09-25 15:55:23,629 - INFO - Cellpose model 'nuclei' initialized successfully\n",
      "2025-09-25 15:55:23,634 - INFO - Neither TORCH CUDA nor MPS version not installed/working.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Nucleus segmentator initialized successfully\n",
      "ðŸ¤– Using model: nuclei\n",
      "âš¡ GPU acceleration: False\n"
     ]
    }
   ],
   "source": [
    "class NucleusSegmentator:\n",
    "    \"\"\"\n",
    "    A robust nucleus segmentation class using Cellpose for cervical cancer cell images.\n",
    "    \n",
    "    This class provides comprehensive nucleus segmentation capabilities including:\n",
    "    - Cellpose-based segmentation with optimized parameters\n",
    "    - Post-processing for nucleus size filtering\n",
    "    - Quality metrics calculation\n",
    "    - Visualization capabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: SegmentationConfig):\n",
    "        \"\"\"\n",
    "        Initialize the nucleus segmentator with configuration.\n",
    "        \n",
    "        Args:\n",
    "            config: SegmentationConfig object containing all parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self._initialize_model()\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        \"\"\"Initialize the Cellpose model.\"\"\"\n",
    "        try:\n",
    "            # Use the correct Cellpose API for model initialization\n",
    "            self.model = models.CellposeModel(gpu=core.use_gpu(), model_type=self.config.model_type)\n",
    "            logger.info(f\"Cellpose model '{self.config.model_type}' initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize Cellpose model: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def preprocess_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Preprocess the input image for optimal segmentation.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image as numpy array\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed image\n",
    "        \"\"\"\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Ensure image is in proper data type and range\n",
    "        if image.dtype != np.uint8:\n",
    "            if image.max() <= 1.0:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image = image.astype(np.uint8)\n",
    "        \n",
    "        # Optional: Apply mild denoising if needed\n",
    "        # image = cv2.bilateralFilter(image, 5, 50, 50)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def segment_nucleus(self, image: np.ndarray, return_flows: bool = False) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Perform nucleus segmentation on a single image.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image as numpy array\n",
    "            return_flows: Whether to return flow field information\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (mask, flows) where flows is None if return_flows=False\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Preprocess image\n",
    "            processed_image = self.preprocess_image(image)\n",
    "            \n",
    "            # Run Cellpose segmentation\n",
    "            masks, flows, styles, diams = self.model.eval(\n",
    "                processed_image,\n",
    "                diameter=self.config.diameter,\n",
    "                channels=self.config.channels,\n",
    "                flow_threshold=self.config.flow_threshold,\n",
    "                cellprob_threshold=self.config.cellprob_threshold\n",
    "            )\n",
    "            \n",
    "            # Post-process masks\n",
    "            masks = self.post_process_masks(masks)\n",
    "            \n",
    "            if return_flows:\n",
    "                return masks, flows\n",
    "            else:\n",
    "                return masks, None\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Segmentation failed: {str(e)}\")\n",
    "            # Return empty mask in case of failure\n",
    "            return np.zeros_like(image[:,:,0] if len(image.shape)==3 else image, dtype=np.uint16), None\n",
    "    \n",
    "    def post_process_masks(self, masks: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Post-process segmentation masks to filter nuclei by size and clean up artifacts.\n",
    "        \n",
    "        Args:\n",
    "            masks: Raw segmentation masks from Cellpose\n",
    "            \n",
    "        Returns:\n",
    "            Cleaned and filtered masks\n",
    "        \"\"\"\n",
    "        if masks.max() == 0:\n",
    "            return masks\n",
    "        \n",
    "        # Get region properties\n",
    "        props = measure.regionprops(masks)\n",
    "        \n",
    "        # Filter regions by area\n",
    "        valid_labels = []\n",
    "        for prop in props:\n",
    "            area = prop.area\n",
    "            if self.config.min_nucleus_size <= area <= self.config.max_nucleus_size:\n",
    "                valid_labels.append(prop.label)\n",
    "        \n",
    "        # Create new mask with only valid nuclei\n",
    "        filtered_mask = np.zeros_like(masks)\n",
    "        for label in valid_labels:\n",
    "            filtered_mask[masks == label] = label\n",
    "        \n",
    "        # Relabel to ensure consecutive numbering\n",
    "        filtered_mask = measure.label(filtered_mask > 0)\n",
    "        \n",
    "        return filtered_mask.astype(np.uint16)\n",
    "    \n",
    "    def calculate_segmentation_metrics(self, image: np.ndarray, mask: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate quality metrics for segmentation results.\n",
    "        \n",
    "        Args:\n",
    "            image: Original image\n",
    "            mask: Segmentation mask\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of quality metrics\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Basic counting metrics\n",
    "        num_nuclei = len(np.unique(mask)) - 1  # Exclude background\n",
    "        metrics['num_nuclei'] = float(num_nuclei)\n",
    "        \n",
    "        # Coverage metrics\n",
    "        total_pixels = image.size if len(image.shape) == 2 else image.shape[0] * image.shape[1]\n",
    "        nucleus_pixels = np.sum(mask > 0)\n",
    "        metrics['nucleus_coverage'] = float(nucleus_pixels / total_pixels)\n",
    "        \n",
    "        # Size metrics\n",
    "        if num_nuclei > 0:\n",
    "            props = measure.regionprops(mask)\n",
    "            areas = [prop.area for prop in props]\n",
    "            metrics['mean_nucleus_area'] = float(np.mean(areas))\n",
    "            metrics['std_nucleus_area'] = float(np.std(areas))\n",
    "            metrics['min_nucleus_area'] = float(np.min(areas))\n",
    "            metrics['max_nucleus_area'] = float(np.max(areas))\n",
    "            \n",
    "            # Circularity metrics\n",
    "            circularities = []\n",
    "            for prop in props:\n",
    "                perimeter = prop.perimeter\n",
    "                area = prop.area\n",
    "                if perimeter > 0:\n",
    "                    circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "                    circularities.append(circularity)\n",
    "            \n",
    "            if circularities:\n",
    "                metrics['mean_circularity'] = float(np.mean(circularities))\n",
    "                metrics['std_circularity'] = float(np.std(circularities))\n",
    "        else:\n",
    "            metrics.update({\n",
    "                'mean_nucleus_area': 0.0,\n",
    "                'std_nucleus_area': 0.0,\n",
    "                'min_nucleus_area': 0.0,\n",
    "                'max_nucleus_area': 0.0,\n",
    "                'mean_circularity': 0.0,\n",
    "                'std_circularity': 0.0\n",
    "            })\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# Initialize the segmentator\n",
    "segmentator = NucleusSegmentator(config)\n",
    "print(\"âœ… Nucleus segmentator initialized successfully\")\n",
    "print(f\"ðŸ¤– Using model: {config.model_type}\")\n",
    "print(f\"âš¡ GPU acceleration: {core.use_gpu()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75026a8",
   "metadata": {},
   "source": [
    "## Batch Processing Functions\n",
    "\n",
    "Now let's implement the batch processing functionality to handle all images in the dataset and create the necessary output folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22dd2575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset processor initialized successfully\n",
      "ðŸ“Š Ready to process 5 cell categories\n"
     ]
    }
   ],
   "source": [
    "class DatasetProcessor:\n",
    "    \"\"\"\n",
    "    Handles batch processing of the entire dataset for nucleus segmentation.\n",
    "    \n",
    "    This class manages:\n",
    "    - Dataset directory traversal\n",
    "    - Output folder creation\n",
    "    - Batch processing with progress tracking\n",
    "    - Results aggregation and reporting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, segmentator: NucleusSegmentator, config: SegmentationConfig):\n",
    "        \"\"\"\n",
    "        Initialize the dataset processor.\n",
    "        \n",
    "        Args:\n",
    "            segmentator: NucleusSegmentator instance\n",
    "            config: SegmentationConfig object\n",
    "        \"\"\"\n",
    "        self.segmentator = segmentator\n",
    "        self.config = config\n",
    "        self.processing_results = []\n",
    "        \n",
    "    def get_image_paths(self, category: str) -> List[Path]:\n",
    "        \"\"\"\n",
    "        Get all image paths for a specific cell category.\n",
    "        \n",
    "        Args:\n",
    "            category: Cell category name\n",
    "            \n",
    "        Returns:\n",
    "            List of image file paths\n",
    "        \"\"\"\n",
    "        input_dir = Path(self.config.dataset_root) / category / self.config.input_folder\n",
    "        if not input_dir.exists():\n",
    "            logger.warning(f\"Input directory does not exist: {input_dir}\")\n",
    "            return []\n",
    "        \n",
    "        # Get all .bmp files and sort them naturally\n",
    "        image_paths = list(input_dir.glob(\"*.bmp\"))\n",
    "        return natsorted(image_paths)\n",
    "    \n",
    "    def create_output_directory(self, category: str) -> Path:\n",
    "        \"\"\"\n",
    "        Create output directory for nucleus masks.\n",
    "        \n",
    "        Args:\n",
    "            category: Cell category name\n",
    "            \n",
    "        Returns:\n",
    "            Path to output directory\n",
    "        \"\"\"\n",
    "        output_dir = Path(self.config.dataset_root) / category / self.config.output_folder\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        logger.info(f\"Output directory created: {output_dir}\")\n",
    "        return output_dir\n",
    "    \n",
    "    def process_single_image(self, image_path: Path, output_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        Process a single image and save the nucleus mask.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to input image\n",
    "            output_path: Path to save output mask\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with processing results and metrics\n",
    "        \"\"\"\n",
    "        result = {\n",
    "            'image_path': str(image_path),\n",
    "            'output_path': str(output_path),\n",
    "            'success': False,\n",
    "            'processing_time': 0.0,\n",
    "            'error_message': None,\n",
    "            'metrics': {}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Load image\n",
    "            image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "            \n",
    "            # Perform segmentation\n",
    "            mask, _ = self.segmentator.segment_nucleus(image)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = self.segmentator.calculate_segmentation_metrics(image, mask)\n",
    "            result['metrics'] = metrics\n",
    "            \n",
    "            # Save mask\n",
    "            cv2.imwrite(str(output_path), mask)\n",
    "            \n",
    "            # Record success\n",
    "            result['success'] = True\n",
    "            result['processing_time'] = time.time() - start_time\n",
    "            \n",
    "            logger.debug(f\"Processed {image_path.name}: {metrics['num_nuclei']} nuclei found\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            result['error_message'] = str(e)\n",
    "            logger.error(f\"Failed to process {image_path}: {str(e)}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def process_category(self, category: str, limit: Optional[int] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Process all images in a specific category.\n",
    "        \n",
    "        Args:\n",
    "            category: Cell category name\n",
    "            limit: Optional limit on number of images to process (for testing)\n",
    "            \n",
    "        Returns:\n",
    "            List of processing results\n",
    "        \"\"\"\n",
    "        logger.info(f\"Processing category: {category}\")\n",
    "        \n",
    "        # Get image paths\n",
    "        image_paths = self.get_image_paths(category)\n",
    "        if not image_paths:\n",
    "            logger.warning(f\"No images found for category {category}\")\n",
    "            return []\n",
    "        \n",
    "        # Apply limit if specified\n",
    "        if limit is not None:\n",
    "            image_paths = image_paths[:limit]\n",
    "            logger.info(f\"Limited to first {limit} images for testing\")\n",
    "        \n",
    "        # Create output directory\n",
    "        output_dir = self.create_output_directory(category)\n",
    "        \n",
    "        # Process each image\n",
    "        category_results = []\n",
    "        \n",
    "        with tqdm(image_paths, desc=f\"Processing {category}\", unit=\"images\") as pbar:\n",
    "            for image_path in pbar:\n",
    "                # Create output filename (same name but different extension)\n",
    "                output_filename = image_path.stem + \"_mask.png\"\n",
    "                output_path = output_dir / output_filename\n",
    "                \n",
    "                # Process image\n",
    "                result = self.process_single_image(image_path, output_path)\n",
    "                result['category'] = category\n",
    "                category_results.append(result)\n",
    "                \n",
    "                # Update progress bar with metrics\n",
    "                if result['success']:\n",
    "                    num_nuclei = result['metrics'].get('num_nuclei', 0)\n",
    "                    pbar.set_postfix({\n",
    "                        'nuclei': int(num_nuclei),\n",
    "                        'coverage': f\"{result['metrics'].get('nucleus_coverage', 0):.2%}\"\n",
    "                    })\n",
    "        \n",
    "        # Log summary\n",
    "        successful_count = sum(1 for r in category_results if r['success'])\n",
    "        logger.info(f\"Category {category}: {successful_count}/{len(category_results)} images processed successfully\")\n",
    "        \n",
    "        return category_results\n",
    "    \n",
    "    def process_all_categories(self, limit_per_category: Optional[int] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Process all categories in the dataset.\n",
    "        \n",
    "        Args:\n",
    "            limit_per_category: Optional limit on images per category (for testing)\n",
    "            \n",
    "        Returns:\n",
    "            List of all processing results\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        logger.info(f\"Starting batch processing of {len(self.config.cell_categories)} categories\")\n",
    "        \n",
    "        for category in self.config.cell_categories:\n",
    "            category_results = self.process_category(category, limit=limit_per_category)\n",
    "            all_results.extend(category_results)\n",
    "        \n",
    "        self.processing_results = all_results\n",
    "        self._log_overall_summary()\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def _log_overall_summary(self):\n",
    "        \"\"\"Log overall processing summary.\"\"\"\n",
    "        if not self.processing_results:\n",
    "            return\n",
    "        \n",
    "        total_images = len(self.processing_results)\n",
    "        successful_images = sum(1 for r in self.processing_results if r['success'])\n",
    "        total_nuclei = sum(r['metrics'].get('num_nuclei', 0) for r in self.processing_results if r['success'])\n",
    "        avg_processing_time = np.mean([r['processing_time'] for r in self.processing_results if r['success']])\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"PROCESSING SUMMARY\")\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(f\"Total images processed: {total_images}\")\n",
    "        logger.info(f\"Successful segmentations: {successful_images}\")\n",
    "        logger.info(f\"Success rate: {successful_images/total_images:.1%}\")\n",
    "        logger.info(f\"Total nuclei detected: {int(total_nuclei)}\")\n",
    "        logger.info(f\"Average processing time: {avg_processing_time:.2f}s\")\n",
    "        logger.info(\"=\"*60)\n",
    "    \n",
    "    def save_results_summary(self, output_path: str):\n",
    "        \"\"\"\n",
    "        Save processing results to a CSV file.\n",
    "        \n",
    "        Args:\n",
    "            output_path: Path to save the results CSV\n",
    "        \"\"\"\n",
    "        if not self.processing_results:\n",
    "            logger.warning(\"No results to save\")\n",
    "            return\n",
    "        \n",
    "        # Prepare data for DataFrame\n",
    "        df_data = []\n",
    "        for result in self.processing_results:\n",
    "            row = {\n",
    "                'category': result.get('category', ''),\n",
    "                'image_path': result['image_path'],\n",
    "                'output_path': result['output_path'],\n",
    "                'success': result['success'],\n",
    "                'processing_time': result['processing_time'],\n",
    "                'error_message': result['error_message'] or '',\n",
    "            }\n",
    "            # Add metrics\n",
    "            row.update(result['metrics'])\n",
    "            df_data.append(row)\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(df_data)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        logger.info(f\"Results summary saved to: {output_path}\")\n",
    "\n",
    "# Initialize dataset processor\n",
    "processor = DatasetProcessor(segmentator, config)\n",
    "print(\"âœ… Dataset processor initialized successfully\")\n",
    "print(f\"ðŸ“Š Ready to process {len(config.cell_categories)} cell categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e22cabd",
   "metadata": {},
   "source": [
    "## Visualization Functions\n",
    "\n",
    "Let's create comprehensive visualization functions to assess the quality of nucleus segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6dcf7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Segmentation visualizer initialized successfully\n",
      "ðŸ“Š Ready to create comprehensive visualizations\n"
     ]
    }
   ],
   "source": [
    "class SegmentationVisualizer:\n",
    "    \"\"\"\n",
    "    Provides comprehensive visualization capabilities for nucleus segmentation results.\n",
    "    \n",
    "    This class creates various visualization types:\n",
    "    - Side-by-side original and mask comparisons\n",
    "    - Overlaid segmentation results\n",
    "    - Statistical summaries\n",
    "    - Quality assessment plots\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: SegmentationConfig):\n",
    "        \"\"\"\n",
    "        Initialize the visualizer.\n",
    "        \n",
    "        Args:\n",
    "            config: SegmentationConfig object\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        plt.style.use('default')  # Ensure consistent plotting style\n",
    "        \n",
    "    def create_colorized_mask(self, mask: np.ndarray, alpha: float = 0.6) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create a colorized version of the segmentation mask.\n",
    "        \n",
    "        Args:\n",
    "            mask: Segmentation mask\n",
    "            alpha: Transparency for overlay\n",
    "            \n",
    "        Returns:\n",
    "            Colorized mask as RGB image\n",
    "        \"\"\"\n",
    "        # Create colormap for different nuclei\n",
    "        colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "        \n",
    "        if mask.max() > 0:\n",
    "            # Use a colormap to assign different colors to different nuclei\n",
    "            unique_labels = np.unique(mask)[1:]  # Exclude background\n",
    "            colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))[:, :3] * 255\n",
    "            \n",
    "            for i, label in enumerate(unique_labels):\n",
    "                colored_mask[mask == label] = colors[i % len(colors)]\n",
    "        \n",
    "        return colored_mask\n",
    "    \n",
    "    def visualize_single_result(self, image: np.ndarray, mask: np.ndarray, \n",
    "                               title: str = \"\", metrics: Optional[Dict] = None,\n",
    "                               save_path: Optional[str] = None) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Create a comprehensive visualization of a single segmentation result.\n",
    "        \n",
    "        Args:\n",
    "            image: Original image\n",
    "            mask: Segmentation mask\n",
    "            title: Plot title\n",
    "            metrics: Optional metrics dictionary\n",
    "            save_path: Optional path to save the figure\n",
    "            \n",
    "        Returns:\n",
    "            Matplotlib figure object\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=self.config.figsize, dpi=self.config.dpi)\n",
    "        fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Original image\n",
    "        axes[0, 0].imshow(image, cmap='gray')\n",
    "        axes[0, 0].set_title('Original Image')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Segmentation mask\n",
    "        axes[0, 1].imshow(mask, cmap='nipy_spectral')\n",
    "        axes[0, 1].set_title(f'Nucleus Mask ({np.max(mask)} nuclei)')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        colored_mask = self.create_colorized_mask(mask)\n",
    "        if len(image.shape) == 2:\n",
    "            overlay_base = np.stack([image, image, image], axis=2)\n",
    "        else:\n",
    "            overlay_base = image\n",
    "        \n",
    "        overlay = cv2.addWeighted(overlay_base.astype(np.uint8), 0.7, \n",
    "                                 colored_mask.astype(np.uint8), 0.3, 0)\n",
    "        axes[1, 0].imshow(overlay)\n",
    "        axes[1, 0].set_title('Overlay')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # Metrics summary\n",
    "        axes[1, 1].axis('off')\n",
    "        if metrics:\n",
    "            metrics_text = self._format_metrics_text(metrics)\n",
    "            axes[1, 1].text(0.1, 0.9, metrics_text, transform=axes[1, 1].transAxes,\n",
    "                           fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'No metrics available', \n",
    "                           transform=axes[1, 1].transAxes, ha='center', va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=self.config.dpi, bbox_inches='tight')\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def _format_metrics_text(self, metrics: Dict) -> str:\n",
    "        \"\"\"Format metrics dictionary into readable text.\"\"\"\n",
    "        lines = ['Segmentation Metrics:', 'â”€' * 20]\n",
    "        \n",
    "        # Basic metrics\n",
    "        lines.append(f\"Nuclei count: {int(metrics.get('num_nuclei', 0))}\")\n",
    "        lines.append(f\"Coverage: {metrics.get('nucleus_coverage', 0):.1%}\")\n",
    "        \n",
    "        # Size metrics\n",
    "        if metrics.get('num_nuclei', 0) > 0:\n",
    "            lines.append('')\n",
    "            lines.append('Size Statistics:')\n",
    "            lines.append(f\"Mean area: {metrics.get('mean_nucleus_area', 0):.1f}px\")\n",
    "            lines.append(f\"Std area: {metrics.get('std_nucleus_area', 0):.1f}px\")\n",
    "            lines.append(f\"Min area: {metrics.get('min_nucleus_area', 0):.1f}px\")\n",
    "            lines.append(f\"Max area: {metrics.get('max_nucleus_area', 0):.1f}px\")\n",
    "            \n",
    "            # Shape metrics\n",
    "            lines.append('')\n",
    "            lines.append('Shape Statistics:')\n",
    "            lines.append(f\"Mean circularity: {metrics.get('mean_circularity', 0):.2f}\")\n",
    "            lines.append(f\"Std circularity: {metrics.get('std_circularity', 0):.2f}\")\n",
    "        \n",
    "        return '\\\\n'.join(lines)\n",
    "    \n",
    "    def compare_multiple_samples(self, samples: List[Tuple[np.ndarray, np.ndarray, str]], \n",
    "                                cols: int = 3, save_path: Optional[str] = None) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Compare multiple segmentation samples in a grid layout.\n",
    "        \n",
    "        Args:\n",
    "            samples: List of (image, mask, title) tuples\n",
    "            cols: Number of columns in the grid\n",
    "            save_path: Optional path to save the figure\n",
    "            \n",
    "        Returns:\n",
    "            Matplotlib figure object\n",
    "        \"\"\"\n",
    "        n_samples = len(samples)\n",
    "        rows = (n_samples + cols - 1) // cols\n",
    "        \n",
    "        fig, axes = plt.subplots(rows * 2, cols, \n",
    "                               figsize=(cols * 5, rows * 6), \n",
    "                               dpi=self.config.dpi)\n",
    "        \n",
    "        if rows == 1 and cols == 1:\n",
    "            axes = axes.reshape(2, 1)\n",
    "        elif rows == 1 or cols == 1:\n",
    "            axes = axes.reshape(rows * 2, -1)\n",
    "        \n",
    "        for idx, (image, mask, title) in enumerate(samples):\n",
    "            col = idx % cols\n",
    "            row_base = (idx // cols) * 2\n",
    "            \n",
    "            # Original image\n",
    "            axes[row_base, col].imshow(image, cmap='gray')\n",
    "            axes[row_base, col].set_title(f'{title} - Original')\n",
    "            axes[row_base, col].axis('off')\n",
    "            \n",
    "            # Mask overlay\n",
    "            colored_mask = self.create_colorized_mask(mask)\n",
    "            if len(image.shape) == 2:\n",
    "                overlay_base = np.stack([image, image, image], axis=2)\n",
    "            else:\n",
    "                overlay_base = image\n",
    "                \n",
    "            overlay = cv2.addWeighted(overlay_base.astype(np.uint8), 0.7, \n",
    "                                     colored_mask.astype(np.uint8), 0.3, 0)\n",
    "            axes[row_base + 1, col].imshow(overlay)\n",
    "            axes[row_base + 1, col].set_title(f'{title} - Segmentation ({np.max(mask)} nuclei)')\n",
    "            axes[row_base + 1, col].axis('off')\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for idx in range(n_samples, rows * cols):\n",
    "            col = idx % cols\n",
    "            row_base = (idx // cols) * 2\n",
    "            if row_base < rows * 2:\n",
    "                axes[row_base, col].axis('off')\n",
    "                axes[row_base + 1, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=self.config.dpi, bbox_inches='tight')\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_metrics_distribution(self, results: List[Dict], save_path: Optional[str] = None) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Plot distribution of segmentation metrics across all processed images.\n",
    "        \n",
    "        Args:\n",
    "            results: List of processing results with metrics\n",
    "            save_path: Optional path to save the figure\n",
    "            \n",
    "        Returns:\n",
    "            Matplotlib figure object\n",
    "        \"\"\"\n",
    "        # Filter successful results and extract metrics\n",
    "        successful_results = [r for r in results if r['success'] and r['metrics']]\n",
    "        \n",
    "        if not successful_results:\n",
    "            fig, ax = plt.subplots(figsize=self.config.figsize)\n",
    "            ax.text(0.5, 0.5, 'No successful results to plot', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            return fig\n",
    "        \n",
    "        # Extract metrics\n",
    "        metrics_df = pd.DataFrame([r['metrics'] for r in successful_results])\n",
    "        categories = [r['category'] for r in successful_results]\n",
    "        metrics_df['category'] = categories\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12), dpi=self.config.dpi)\n",
    "        fig.suptitle('Nucleus Segmentation Metrics Distribution', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot distributions\n",
    "        metrics_to_plot = [\n",
    "            ('num_nuclei', 'Number of Nuclei'),\n",
    "            ('nucleus_coverage', 'Nucleus Coverage'),\n",
    "            ('mean_nucleus_area', 'Mean Nucleus Area (px)'),\n",
    "            ('mean_circularity', 'Mean Circularity'),\n",
    "            ('processing_time', 'Processing Time (s)')\n",
    "        ]\n",
    "        \n",
    "        for idx, (metric, title) in enumerate(metrics_to_plot):\n",
    "            if idx >= 6:\n",
    "                break\n",
    "                \n",
    "            row, col = idx // 3, idx % 3\n",
    "            ax = axes[row, col]\n",
    "            \n",
    "            if metric == 'processing_time':\n",
    "                # Use processing time from results\n",
    "                data = [r['processing_time'] for r in successful_results]\n",
    "                category_data = categories\n",
    "            else:\n",
    "                data = metrics_df[metric].values\n",
    "                category_data = metrics_df['category'].values\n",
    "            \n",
    "            # Create boxplot by category\n",
    "            category_data_dict = {}\n",
    "            for cat in self.config.cell_categories:\n",
    "                mask = [c == cat for c in category_data]\n",
    "                category_data_dict[cat.replace('im_', '')] = [d for d, m in zip(data, mask) if m]\n",
    "            \n",
    "            if category_data_dict:\n",
    "                ax.boxplot(category_data_dict.values(), labels=category_data_dict.keys())\n",
    "                ax.set_title(title)\n",
    "                ax.tick_params(axis='x', rotation=45)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(title)\n",
    "        \n",
    "        # Overall statistics in the last subplot\n",
    "        ax = axes[1, 2]\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Calculate overall stats\n",
    "        total_images = len(successful_results)\n",
    "        total_nuclei = sum(r['metrics']['num_nuclei'] for r in successful_results)\n",
    "        avg_coverage = np.mean([r['metrics']['nucleus_coverage'] for r in successful_results])\n",
    "        avg_time = np.mean([r['processing_time'] for r in successful_results])\n",
    "        \n",
    "        stats_text = f\"\"\"Overall Statistics\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        Total Images: {total_images}\n",
    "        Total Nuclei: {int(total_nuclei)}\n",
    "        Avg Coverage: {avg_coverage:.1%}\n",
    "        Avg Time: {avg_time:.2f}s\n",
    "        \n",
    "        Success Rate: {len(successful_results)/len(results):.1%}\n",
    "        \"\"\"\n",
    "        \n",
    "        ax.text(0.1, 0.9, stats_text, transform=ax.transAxes,\n",
    "               fontsize=11, verticalalignment='top', fontfamily='monospace')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=self.config.dpi, bbox_inches='tight')\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = SegmentationVisualizer(config)\n",
    "print(\"âœ… Segmentation visualizer initialized successfully\")\n",
    "print(\"ðŸ“Š Ready to create comprehensive visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ba1f1",
   "metadata": {},
   "source": [
    "## Full Dataset Processing\n",
    "\n",
    "Once the test is successful, you can process the entire dataset using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5382992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 16:17:58,380 - INFO - Starting batch processing of 5 categories\n",
      "2025-09-25 16:17:58,382 - INFO - Processing category: im_Dyskeratotic\n",
      "2025-09-25 16:17:58,382 - INFO - Processing category: im_Dyskeratotic\n",
      "2025-09-25 16:17:58,435 - INFO - Output directory created: c:\\Meet\\Projects\\Project_8_Phoenix_Cervical Cancer Image Classification\\Project-Phoenix\\Dataset\\Augmented Dataset - Limited Enhancement\\im_Dyskeratotic\\Nucleus Masks\n",
      "2025-09-25 16:17:58,435 - INFO - Output directory created: c:\\Meet\\Projects\\Project_8_Phoenix_Cervical Cancer Image Classification\\Project-Phoenix\\Dataset\\Augmented Dataset - Limited Enhancement\\im_Dyskeratotic\\Nucleus Masks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting full dataset processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a1b7ad67c84afdb3981fbe2ba91460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing im_Dyskeratotic:   0%|          | 0/813 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 16:17:58,460 - WARNING - channels deprecated in v4.0.1+. If data contain more than 3 channels, only the first 3 channels will be used\n",
      "2025-09-25 16:51:07,255 - ERROR - Segmentation failed: not enough values to unpack (expected 4, got 3)\n",
      "2025-09-25 16:51:07,332 - WARNING - channels deprecated in v4.0.1+. If data contain more than 3 channels, only the first 3 channels will be used\n",
      "2025-09-25 16:51:07,255 - ERROR - Segmentation failed: not enough values to unpack (expected 4, got 3)\n",
      "2025-09-25 16:51:07,332 - WARNING - channels deprecated in v4.0.1+. If data contain more than 3 channels, only the first 3 channels will be used\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸš€ Starting full dataset processing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_all_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m      5\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 178\u001b[0m, in \u001b[0;36mDatasetProcessor.process_all_categories\u001b[1;34m(self, limit_per_category)\u001b[0m\n\u001b[0;32m    175\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting batch processing of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcell_categories)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m categories\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcell_categories:\n\u001b[1;32m--> 178\u001b[0m     category_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit_per_category\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mextend(category_results)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_results \u001b[38;5;241m=\u001b[39m all_results\n",
      "Cell \u001b[1;32mIn[9], line 145\u001b[0m, in \u001b[0;36mDatasetProcessor.process_category\u001b[1;34m(self, category, limit)\u001b[0m\n\u001b[0;32m    142\u001b[0m output_path \u001b[38;5;241m=\u001b[39m output_dir \u001b[38;5;241m/\u001b[39m output_filename\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Process image\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_single_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m category\n\u001b[0;32m    147\u001b[0m category_results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[9], line 87\u001b[0m, in \u001b[0;36mDatasetProcessor.process_single_image\u001b[1;34m(self, image_path, output_path)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Perform segmentation\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m mask, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegmentator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegment_nucleus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m     90\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentator\u001b[38;5;241m.\u001b[39mcalculate_segmentation_metrics(image, mask)\n",
      "Cell \u001b[1;32mIn[8], line 75\u001b[0m, in \u001b[0;36mNucleusSegmentator.segment_nucleus\u001b[1;34m(self, image, return_flows)\u001b[0m\n\u001b[0;32m     72\u001b[0m processed_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_image(image)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Run Cellpose segmentation\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m masks, flows, styles, diams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessed_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiameter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcellprob_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcellprob_threshold\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Post-process masks\u001b[39;00m\n\u001b[0;32m     84\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_process_masks(masks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\cellpose\\models.py:313\u001b[0m, in \u001b[0;36mCellposeModel.eval\u001b[1;34m(self, x, batch_size, resample, channels, channel_axis, z_axis, normalize, invert, rescale, diameter, flow_threshold, cellprob_threshold, do_3D, anisotropy, flow3D_smooth, stitch_threshold, min_size, max_size_fraction, niter, augment, tile_overlap, bsize, compute_masks, progress)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(anisotropy, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m image_scaling:\n\u001b[0;32m    311\u001b[0m     anisotropy \u001b[38;5;241m=\u001b[39m image_scaling \u001b[38;5;241m*\u001b[39m anisotropy\n\u001b[1;32m--> 313\u001b[0m dP, cellprob, styles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_net\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile_overlap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_3D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_3D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43manisotropy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manisotropy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_3D:    \n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flow3D_smooth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\cellpose\\models.py:478\u001b[0m, in \u001b[0;36mCellposeModel._run_net\u001b[1;34m(self, x, augment, batch_size, tile_overlap, bsize, anisotropy, do_3D)\u001b[0m\n\u001b[0;32m    476\u001b[0m     dP \u001b[38;5;241m=\u001b[39m yf[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m     yf, styles \u001b[38;5;241m=\u001b[39m \u001b[43mrun_net\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtile_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile_overlap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m     cellprob \u001b[38;5;241m=\u001b[39m yf[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    483\u001b[0m     dP \u001b[38;5;241m=\u001b[39m yf[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\cellpose\\core.py:230\u001b[0m, in \u001b[0;36mrun_net\u001b[1;34m(net, imgi, batch_size, augment, tile_overlap, bsize, rsz)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, IMGa\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], batch_size):\n\u001b[0;32m    229\u001b[0m     bslc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(j, \u001b[38;5;28mmin\u001b[39m(j \u001b[38;5;241m+\u001b[39m batch_size, IMGa\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m--> 230\u001b[0m     ya0, stylea0 \u001b[38;5;241m=\u001b[39m \u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMGa\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbslc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    232\u001b[0m         nout \u001b[38;5;241m=\u001b[39m ya0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\cellpose\\core.py:158\u001b[0m, in \u001b[0;36m_forward\u001b[1;34m(net, x)\u001b[0m\n\u001b[0;32m    156\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 158\u001b[0m     y, style \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X\n\u001b[0;32m    160\u001b[0m y \u001b[38;5;241m=\u001b[39m _from_device(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\cellpose\\vit_sam.py:70\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m---> 70\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mneck(x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# readout is changed here\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\segment_anything\\modeling\\image_encoder.py:174\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    171\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    172\u001b[0m     x, pad_hw \u001b[38;5;241m=\u001b[39m window_partition(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[1;32m--> 174\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# Reverse window partition\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\segment_anything\\modeling\\image_encoder.py:227\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    225\u001b[0m B, H, W, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# qkv with shape (3, B, nHead, H * W, C)\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqkv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(B, H \u001b[38;5;241m*\u001b[39m W, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# q, k, v with shape (B * nHead, H * W, C)\u001b[39;00m\n\u001b[0;32m    229\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m3\u001b[39m, B \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, H \u001b[38;5;241m*\u001b[39m W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ Starting full dataset processing...\")\n",
    "all_results = processor.process_all_categories()\n",
    "\n",
    "# Save results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_path = f\"nucleus_segmentation_results_{timestamp}.csv\"\n",
    "processor.save_results_summary(results_path)\n",
    "\n",
    "print(f\"ðŸ’¾ Results saved to: {results_path}\")\n",
    "\n",
    "# print(\"âš ï¸ Full dataset processing is commented out for safety.\")\n",
    "# print(\"ðŸ“ Uncomment the above code to process all images in the dataset.\")\n",
    "# print(\"â±ï¸ Expected processing time: Several hours depending on your system.\")\n",
    "# print(\"ðŸ’½ This will create 'Nucleus Masks' folders in each cell category directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d51cd",
   "metadata": {},
   "source": [
    "## Usage Instructions and Documentation\n",
    "\n",
    "This notebook provides a complete nucleus segmentation pipeline for cervical cancer cell images. Here's how to use it:\n",
    "\n",
    "### ðŸš€ Quick Start Guide\n",
    "\n",
    "1. **Environment Setup**: All required libraries are already imported and configured\n",
    "2. **Single Image Test**: Run the test cell above to verify segmentation on one image\n",
    "3. **Full Processing**: Uncomment and run the full processing cell to handle all images\n",
    "4. **Results**: Check the created `Nucleus Masks` folders in each cell category directory\n",
    "\n",
    "### ðŸ“ Directory Structure\n",
    "\n",
    "The system expects this directory structure:\n",
    "```\n",
    "Dataset Root/\n",
    "â”œâ”€â”€ im_Dyskeratotic/\n",
    "â”‚   â”œâ”€â”€ NLM_CLAHE/           # Input images (.bmp files)\n",
    "â”‚   â””â”€â”€ Nucleus Masks/       # Generated masks (.png files)\n",
    "â”œâ”€â”€ im_Koilocytotic/\n",
    "â”‚   â”œâ”€â”€ NLM_CLAHE/\n",
    "â”‚   â””â”€â”€ Nucleus Masks/\n",
    "... (and so on for all 5 categories)\n",
    "```\n",
    "\n",
    "### ðŸ”§ Configuration Options\n",
    "\n",
    "Key parameters you can modify in the `SegmentationConfig` class:\n",
    "\n",
    "- **`model_type`**: Cellpose model to use ('nuclei', 'cyto', 'cyto2')\n",
    "- **`diameter`**: Expected nucleus diameter (None for auto-estimation)\n",
    "- **`flow_threshold`**: Flow error threshold (0.4 default)\n",
    "- **`cellprob_threshold`**: Cell probability threshold (0.0 default)\n",
    "- **`min_nucleus_size`**: Minimum nucleus area in pixels (50 default)\n",
    "- **`max_nucleus_size`**: Maximum nucleus area in pixels (5000 default)\n",
    "\n",
    "### ðŸ“Š Output Files\n",
    "\n",
    "For each processed image, the system generates:\n",
    "\n",
    "1. **Nucleus Mask**: PNG file with segmented nuclei (each nucleus has a unique integer ID)\n",
    "2. **CSV Results**: Summary file with metrics for all processed images including:\n",
    "   - Number of nuclei detected\n",
    "   - Nucleus coverage percentage\n",
    "   - Area and circularity statistics\n",
    "   - Processing times\n",
    "   - Success/failure status\n",
    "\n",
    "### ðŸŽ¯ Key Features\n",
    "\n",
    "- **Robust Segmentation**: Uses state-of-the-art Cellpose model optimized for nuclei\n",
    "- **Quality Control**: Size-based filtering to remove artifacts and oversegmented regions\n",
    "- **Comprehensive Metrics**: Detailed statistics on segmentation quality\n",
    "- **Visualization Tools**: Side-by-side comparisons and overlay visualizations\n",
    "- **Batch Processing**: Efficiently handles thousands of images with progress tracking\n",
    "- **Error Handling**: Graceful failure handling with detailed logging\n",
    "\n",
    "### ðŸ“ˆ Quality Assessment\n",
    "\n",
    "The system provides multiple ways to assess segmentation quality:\n",
    "\n",
    "1. **Visual Inspection**: Overlay visualizations show original images with detected nuclei\n",
    "2. **Statistical Metrics**: Coverage, size, and shape statistics for quality control\n",
    "3. **Comparative Analysis**: Box plots showing distributions across cell categories\n",
    "4. **Processing Reports**: Success rates and error logs for troubleshooting\n",
    "\n",
    "### âš™ï¸ Performance Considerations\n",
    "\n",
    "- **CPU vs GPU**: System automatically detects GPU availability (CPU fallback included)\n",
    "- **Memory Usage**: Images processed individually to minimize memory requirements\n",
    "- **Processing Time**: Expect ~1-5 seconds per image on CPU, faster with GPU\n",
    "- **Disk Space**: Mask images are typically smaller than originals (lossless PNG compression)\n",
    "\n",
    "### ðŸ”¬ Scientific Applications\n",
    "\n",
    "This nucleus segmentation pipeline enables:\n",
    "\n",
    "1. **Explainable AI**: Understanding which cellular regions drive model decisions\n",
    "2. **Morphometric Analysis**: Quantitative analysis of nucleus size, shape, and distribution\n",
    "3. **Disease Characterization**: Statistical comparison of nucleus features across cell types\n",
    "4. **Quality Control**: Automated detection of segmentation failures and outliers\n",
    "5. **Standardization**: Consistent nucleus detection across large datasets\n",
    "\n",
    "### ðŸ“š References and Methods\n",
    "\n",
    "- **Cellpose**: Stringer, C. et al. \"Cellpose: a generalist algorithm for cellular segmentation.\" Nature Methods (2021)\n",
    "- **Nucleus Detection**: Optimized for cervical cancer cell morphology\n",
    "- **Post-processing**: Size filtering and morphological operations for quality improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
